{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common_lib import DataManager\n",
    "from common_lib import AnnotationManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from tqdm.notebook import tqdm\n",
    "import timm\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "seed = 42\n",
    "lr = 0.003\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device =  torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed): #将所有的随机变量设置其随机种子\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据加载和类型设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_root = \"F:/mountMl_fan/bearing/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = DataManager.load(\"./jsons/train.json\")\n",
    "val_data = DataManager.load(\"./jsons/val.json\")\n",
    "test_data = DataManager.load(\"./jsons/test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "am = AnnotationManager(train_data.class_dict)\n",
    "am.setup_distribution_type(\n",
    "    distribution_classes = am._all_classes,\n",
    "    distribution_type = 'multilabel'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rec = train_data[0]\n",
    "# print(rec)\n",
    "# am.get_distribution(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 多标签分类\n",
    "class CharacterDataset(Dataset): #定义数据集 定义len getitem函数 重写len 和getitem魔法方法\n",
    "    def __init__(self, data,am,_root,transform=None):  #设置文件和对应的转换操作\n",
    "        self.file= data\n",
    "        self.transform = transform\n",
    "        self.img_root = img_root\n",
    "        self.am = am\n",
    "    def __len__(self):\n",
    "        self.filelen = len(self.file)\n",
    "        return self.filelen\n",
    "\n",
    "    def __getitem__(self, idx): #p[key] 取值，当实例对象做p[key] 运算时，会调用类中的方法__getitem__\n",
    "        rec = self.file[idx]\n",
    "        img_path = self.img_root+rec['info']['image_path']\n",
    "        img = Image.open(img_path)\n",
    "#         img = img.convert(\"RGB\")\n",
    "        img_transformed = self.transform(img)\n",
    "#         am = AnnotationManager(self.file.class_dict)\n",
    "        label = self.am.get_distribution(rec) #使用传入的am 形式为[0] 选取[0]\n",
    "        label = torch.tensor(label)\n",
    "#         label = img_path.split(os.path.sep)[-1].split(\".\")[0]\n",
    "#         label = 1 if label == \"dog\" else 0 #如果标签为dog 则设置为1 否则为0（狗为1 猫为0）\n",
    "#         print(label)\n",
    "        return img_transformed, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练集 验证集 测试集 处理为相同的图像增强操作\n",
    "train_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((224, 224)),  # 将给定图像随机裁剪为不同的大小和宽高比，然后缩放所裁剪得到的图像为制定的大小；\n",
    "#         transforms.RandomHorizontalFlip(),  # 以给定的概率随机水平旋转给定的PIL的图像，默认为0.5；\n",
    "        transforms.ToTensor(),              # 归一化 并且转化为张量\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((224, 224)),\n",
    "#         transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "test_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((224, 224)),\n",
    "#         transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CharacterDataset(train_data,am,img_root, transform=train_transforms)  \n",
    "valid_dataset = CharacterDataset(val_data,am,img_root, transform=test_transforms)\n",
    "test_dataset = CharacterDataset(test_data,am,img_root, transform=test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset = train_dataset, batch_size=batch_size, shuffle=True )\n",
    "valid_loader = DataLoader(dataset = valid_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset = test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预览数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for data,label in train_loader:\n",
    "#     fig, axes = plt.subplots(4, 4, figsize=(12, 12))\n",
    "#     print(data.shape)\n",
    "#     print(label)\n",
    "#     print(len(label),len(label[0]))\n",
    "#     for idx, ax in enumerate(axes.ravel()):\n",
    "#         img = data[idx].permute(1, 2, 0)\n",
    "#         ax.set_title(label[idx]) #轴添加\n",
    "#         ax.imshow(img,cmap=\"gray\")\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型构建"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多标签的评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]))"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y =  torch.tensor([1.,0.,1.,1])\n",
    "pre = torch.tensor([0.1,0.2,0.4,0.6])>0.5\n",
    "pre = pre.float()\n",
    "pre,pre*y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1000, 0.2000, 0.4000, 0.6000],\n",
       "        [0.9000, 0.2000, 0.4000, 0.6000]])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[0.1,0.2,0.4,0.6],[0.9,0.2,0.4,0.6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算准确率——方式1\n",
    "# 设定一个阈值，当预测的概率值大于这个阈值，则认为这幅图像中含有这类标签\n",
    "def calculate_acuracy_mode_one(model_pred, labels,accuracy_th): \n",
    "    # 注意这里的model_pred是经过sigmoid处理的，sigmoid处理后可以视为预测是这一类的概率\n",
    "    # 预测结果，大于这个阈值则视为预测正确\n",
    "#     accuracy_th = 0.5\n",
    "    pred_result = model_pred > accuracy_th\n",
    "    pred_result = pred_result.float()      #将bool的变量转化为float类型 \n",
    "    pred_one_num = torch.sum(pred_result)  #预测为1的个数\n",
    "    if pred_one_num == 0:\n",
    "        return 0, 0\n",
    "    target_one_num = torch.sum(labels)\n",
    "    true_predict_num = torch.sum(pred_result * labels) #做交集再求和 也就是TP的个数\n",
    "    # 模型预测的结果中有多少个是正确的\n",
    "    precision = true_predict_num / pred_one_num\n",
    "    # 模型预测正确的结果中，占所有真实标签的数量\n",
    "    recall = true_predict_num / target_one_num\n",
    "#     return precision, recall\n",
    " \n",
    "    return precision.item(), recall.item()\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算准确率——方式2\n",
    "# 取预测概率最大的前top个标签，作为模型的预测结果\n",
    "def calculate_acuracy_mode_two_for_item(model_pred, labels,top):  #整体\n",
    "    # 取前top个预测结果作为模型的预测结果\n",
    "    precision = 0\n",
    "    recall = 0\n",
    "    # 对预测结果进行按概率值进行降序排列，取概率最大的top个结果作为模型的预测结果\n",
    "    pred_label_locate  = torch.argsort(model_pred, descending=True)[0:top]  #按照降序排序 排序的结果是其下标 默认按照最后一个维度排序\n",
    "    print(pred_label_locate )\n",
    "    temp_label = torch.zeros(model_pred.shape[0])\n",
    "    temp_label[pred_label_locate ] = 1  #将其一张图片对象的预测结果输出\n",
    "    print(temp_label)\n",
    "    target_one_num = torch.sum(labels)\n",
    "    true_predict_num = torch.sum(temp_label * labels)\n",
    "        # 对每一幅图像进行预测准确率的计算\n",
    "    precision += true_predict_num / top #预测的T中对了几个\n",
    "        # 对每一幅图像进行预测查全率的计算\n",
    "    recall += true_predict_num / target_one_num\n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算准确率——方式2\n",
    "# 取预测概率最大的前top个标签，作为模型的预测结果\n",
    "def calculate_acuracy_mode_two(model_pred, labels,top):\n",
    "    # 取前top个预测结果作为模型的预测结果\n",
    "    precision = 0\n",
    "    recall = 0\n",
    "#     top = 5\n",
    "    # 对预测结果进行按概率值进行降序排列，取概率最大的top个结果作为模型的预测结果\n",
    "    pred_label_locate = torch.argsort(model_pred, descending=True)[:, 0:top]\n",
    "    for i in range(model_pred.shape[0]):\n",
    "        temp_label = torch.zeros(1, model_pred.shape[1])\n",
    "        temp_label[0,pred_label_locate[i]] = 1\n",
    "        target_one_num = torch.sum(labels[i])\n",
    "        true_predict_num = torch.sum(temp_label * labels[i])\n",
    "        # 对每一幅图像进行预测准确率的计算\n",
    "        print(precision,recall)\n",
    "        precision += true_predict_num / top\n",
    "        # 对每一幅图像进行预测查全率的计算\n",
    "        recall += true_predict_num / target_one_num\n",
    "    return (precision/model_pred.shape[0]).item(), (recall/model_pred.shape[0]).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 测试\n",
    "# model_pred = torch.tensor([[0.6,0.55,0.2,0.1],[0.6,0.1,0.7,0.1]])\n",
    "# labels = torch.tensor([[1,0,0,0],[1,0,1,0]])\n",
    "\n",
    "# # model_pred = torch.tensor([0.6,0.6,0.2,0.1])\n",
    "# # labels = torch.tensor([1,0,0,0])\n",
    "# # model_pred.shape[0]\n",
    "# calculate_acuracy_mode_one(model_pred,labels,0.5),calculate_acuracy_mode_two(model_pred,labels,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vit_deit_base_distilled_patch16_224',\n",
       " 'vit_deit_base_distilled_patch16_384',\n",
       " 'vit_deit_base_patch16_224',\n",
       " 'vit_deit_base_patch16_384',\n",
       " 'vit_deit_small_distilled_patch16_224',\n",
       " 'vit_deit_small_patch16_224',\n",
       " 'vit_deit_tiny_distilled_patch16_224',\n",
       " 'vit_deit_tiny_patch16_224']"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timm.list_models(\"*deit*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "class multiLabel_net(nn.Module):\n",
    "    def __init__(self,n_classes,pretrained = False):\n",
    "        super(multiLabel_net,self).__init__()\n",
    "        self.model = timm.create_model(\"vit_deit_tiny_distilled_patch16_224\",pretrained=pretrained,in_chans =1,num_classes=n_classes)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x,_= self.model(x)\n",
    "        x = torch.sigmoid(x)   #方法\n",
    "        return x\n",
    "    def train_one_epoch(self,train_loader,criterion,optimizer,device,accuracy_th=0.5):\n",
    "        epoch_loss = 0.0\n",
    "        epoch_precision = 0.0\n",
    "        epoch_recall = 0.0\n",
    "        self.model.train()\n",
    "        for i,(data,target) in enumerate(train_loader): #每一个批次的最后进行参数更新\n",
    "            if device.type==\"cuda\":\n",
    "                data,target = data.cuda(),target.cuda()\n",
    "            optimizer.zero_grad()  #变量的梯度清零\n",
    "#             output,aux = self.forward(data) #训练输出结果\n",
    "            output = self.forward(data) #训练输出结果\n",
    "    \n",
    "#             print(target[0],output[0])\n",
    "#             temp = ClassifierEvalMultilabel.compute_ap(target.detach().numpy(),output.detach().numpy())\n",
    "#             print(temp)\n",
    "#             for y_true,y_score in zip(target,output):\n",
    "#                 y_true = y_true.detach().numpy()\n",
    "#                 y_score = y_score.detach().numpy()\n",
    "#                 print(y_true,y_score)\n",
    "#                 temp = ClassifierEvalMultilabel.compute_ap(y_true,y_score) \n",
    "#                 print(temp)\n",
    "\n",
    "            loss = criterion(output,target) #求解loss\n",
    "            precision, recall = calculate_acuracy_mode_one(output,target,accuracy_th) \n",
    "            epoch_loss += loss\n",
    "            epoch_precision += precision\n",
    "            epoch_recall += recall   \n",
    "            \n",
    "            loss.backward() #计算每个参数的梯度值\n",
    "            optimizer.step()  #参数根据梯度进行更新\n",
    "            \n",
    "            if(i%100==99):\n",
    "                print(f\"第{i+1}批次 loss: {loss:.4f} precision: {precision:.4f} recall: {recall:.4f} \\n\")\n",
    "        return epoch_loss/len(train_loader),epoch_precision/len(train_loader),epoch_recall/len(train_loader)\n",
    "    def validation_one_epoch(self,valid_loader,criterion,device,accuracy_th=0.5):\n",
    "        valid_loss = 0.0\n",
    "        valid_precision = 0.0\n",
    "        valid_recall = 0.0\n",
    "        self.model.eval()   #可以屏蔽BN层和dropout\n",
    "        for data,target in valid_loader:\n",
    "            if device.type==\"cuda\":\n",
    "                data,target = data.cuda(),target.cuda()\n",
    "            with torch.no_grad():\n",
    "                output = self.model(data)\n",
    "                output = torch.sigmoid(output)\n",
    "#                 print(output)\n",
    "                loss = criterion(output,target)\n",
    "                valid_loss += loss\n",
    "                precision, recall = calculate_acuracy_mode_one(output,target,accuracy_th) \n",
    "                valid_precision += precision\n",
    "                valid_recall += recall   \n",
    "        return valid_loss/len(valid_loader),valid_precision/len(valid_loader),valid_recall/len(valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = multiLabel_net(n_classes=len(am._all_classes),pretrained=True)\n",
    "model.to(device)\n",
    "criterion = nn.BCELoss ()  #BCELoss 需要先进行sigmoid  BCEWithLogitsLoss会包含sigmoid和BCE两部\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr) #传入模型参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第1轮---------------------------------》》》》》》\n",
      "\n",
      "第100批次 loss: 0.1491 precision: 0.7500 recall: 0.3750 \n",
      "\n",
      "第200批次 loss: 0.1581 precision: 0.8125 recall: 0.4062 \n",
      "\n",
      "第300批次 loss: 0.1511 precision: 0.7500 recall: 0.3750 \n",
      "\n",
      "第400批次 loss: 0.1574 precision: 0.6875 recall: 0.3438 \n",
      "\n",
      "第500批次 loss: 0.1511 precision: 0.7500 recall: 0.3750 \n",
      "\n",
      "第600批次 loss: 0.1523 precision: 0.7500 recall: 0.3750 \n",
      "\n",
      "第700批次 loss: 0.1553 precision: 0.6875 recall: 0.3438 \n",
      "\n",
      "第800批次 loss: 0.1407 precision: 0.9375 recall: 0.4688 \n",
      "\n",
      "第900批次 loss: 0.1497 precision: 0.8125 recall: 0.4062 \n",
      "\n",
      "第1000批次 loss: 0.1576 precision: 0.6250 recall: 0.3125 \n",
      "\n",
      "第1100批次 loss: 0.1514 precision: 0.8125 recall: 0.4062 \n",
      "\n",
      "第1200批次 loss: 0.1364 precision: 0.8750 recall: 0.4375 \n",
      "\n",
      "第1300批次 loss: 0.1351 precision: 0.6875 recall: 0.3438 \n",
      "\n",
      "第1400批次 loss: 0.1306 precision: 0.8125 recall: 0.4062 \n",
      "\n",
      "第1500批次 loss: 0.1368 precision: 0.8125 recall: 0.4062 \n",
      "\n",
      "第1600批次 loss: 0.1286 precision: 0.6842 recall: 0.4062 \n",
      "\n",
      "第1700批次 loss: 0.1265 precision: 0.8125 recall: 0.4062 \n",
      "\n",
      "第1800批次 loss: 0.1171 precision: 0.8750 recall: 0.4375 \n",
      "\n",
      "第1900批次 loss: 0.1251 precision: 0.8125 recall: 0.4062 \n",
      "\n",
      "第2000批次 loss: 0.1193 precision: 0.8125 recall: 0.4062 \n",
      "\n",
      "第2100批次 loss: 0.1329 precision: 0.6250 recall: 0.3125 \n",
      "\n",
      "第2200批次 loss: 0.1204 precision: 0.7222 recall: 0.4062 \n",
      "\n",
      "Epoch : 1 - loss : 0.1424 - acc: 0.7359 -train_reacall: 0.3706 - val_loss : 0.1958 - val_acc: 0.5315 -val_recall: 0.2048\n",
      "\n",
      "第2轮---------------------------------》》》》》》\n",
      "\n",
      "第100批次 loss: 0.1427 precision: 0.6875 recall: 0.3438 \n",
      "\n",
      "第200批次 loss: 0.1023 precision: 0.7500 recall: 0.3750 \n",
      "\n",
      "第300批次 loss: 0.1039 precision: 0.8824 recall: 0.4688 \n",
      "\n",
      "第400批次 loss: 0.1179 precision: 0.7059 recall: 0.3750 \n",
      "\n",
      "第500批次 loss: 0.0993 precision: 0.8235 recall: 0.4375 \n",
      "\n",
      "第600批次 loss: 0.1271 precision: 0.7059 recall: 0.3750 \n",
      "\n",
      "第700批次 loss: 0.1020 precision: 0.7647 recall: 0.4062 \n",
      "\n",
      "第800批次 loss: 0.1149 precision: 0.8333 recall: 0.4688 \n",
      "\n",
      "第900批次 loss: 0.1083 precision: 0.8750 recall: 0.4375 \n",
      "\n",
      "第1000批次 loss: 0.1022 precision: 0.7143 recall: 0.4688 \n",
      "\n",
      "第1100批次 loss: 0.1038 precision: 0.8421 recall: 0.5000 \n",
      "\n",
      "第1200批次 loss: 0.0993 precision: 0.7778 recall: 0.4375 \n",
      "\n",
      "第1300批次 loss: 0.1244 precision: 0.6667 recall: 0.3750 \n",
      "\n",
      "第1400批次 loss: 0.1190 precision: 0.6250 recall: 0.3125 \n",
      "\n",
      "第1500批次 loss: 0.0995 precision: 0.9000 recall: 0.5625 \n",
      "\n",
      "第1600批次 loss: 0.1182 precision: 0.8235 recall: 0.4375 \n",
      "\n",
      "第1700批次 loss: 0.1157 precision: 0.7647 recall: 0.4062 \n",
      "\n",
      "第1800批次 loss: 0.1318 precision: 0.8125 recall: 0.4062 \n",
      "\n",
      "第1900批次 loss: 0.1391 precision: 0.5882 recall: 0.3125 \n",
      "\n",
      "第2000批次 loss: 0.1199 precision: 1.0000 recall: 0.5000 \n",
      "\n",
      "第2100批次 loss: 0.1529 precision: 0.4706 recall: 0.2500 \n",
      "\n",
      "第2200批次 loss: 0.1389 precision: 0.4375 recall: 0.2188 \n",
      "\n",
      "Epoch : 2 - loss : 0.1188 - acc: 0.7591 -train_reacall: 0.4075 - val_loss : 0.1889 - val_acc: 0.5023 -val_recall: 0.2368\n",
      "\n",
      "第3轮---------------------------------》》》》》》\n",
      "\n",
      "第100批次 loss: 0.1318 precision: 0.7500 recall: 0.3750 \n",
      "\n",
      "第200批次 loss: 0.1357 precision: 0.6250 recall: 0.3125 \n",
      "\n",
      "第300批次 loss: 0.1455 precision: 0.5882 recall: 0.3125 \n",
      "\n",
      "第400批次 loss: 0.1290 precision: 0.6875 recall: 0.3438 \n",
      "\n",
      "第500批次 loss: 0.1162 precision: 0.8125 recall: 0.4062 \n",
      "\n",
      "第600批次 loss: 0.1113 precision: 0.8125 recall: 0.4062 \n",
      "\n",
      "第700批次 loss: 0.1341 precision: 0.5294 recall: 0.2812 \n",
      "\n",
      "第800批次 loss: 0.1285 precision: 0.8125 recall: 0.4062 \n",
      "\n",
      "第900批次 loss: 0.1351 precision: 0.7500 recall: 0.3750 \n",
      "\n",
      "第1000批次 loss: 0.1562 precision: 0.6250 recall: 0.3125 \n",
      "\n",
      "第1100批次 loss: 0.1339 precision: 0.6875 recall: 0.3438 \n",
      "\n",
      "第1200批次 loss: 0.1329 precision: 0.8125 recall: 0.4062 \n",
      "\n",
      "第1300批次 loss: 0.1617 precision: 0.6250 recall: 0.3125 \n",
      "\n",
      "第1400批次 loss: 0.1153 precision: 0.8125 recall: 0.4062 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    print(f\"第{epoch+1}轮---------------------------------》》》》》》\\n\")\n",
    "    epoch_loss,epoch_precision,epoch_recall = model.train_one_epoch(train_loader, criterion, optimizer, device,0.5)\n",
    "    epoch_val_loss,epoch_val_precision,epoch_val_recall = model.validation_one_epoch(valid_loader,criterion,device,0.5)\n",
    "    print(\n",
    "        f\"Epoch : {epoch+1} - loss : {epoch_loss:.4f} - acc: {epoch_precision:.4f} -train_reacall: {epoch_recall:.4f} - val_loss : {epoch_val_loss:.4f} - val_acc: {epoch_val_precision:.4f} -val_recall: {epoch_val_recall:.4f}\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 类别和评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classifier_eval import ClassifierEvalBinary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_Ap_Adraw(batch_pred,batch_label,class_name):\n",
    "    ap_list = []\n",
    "    num_classes = batch_label.shape[1]\n",
    "    for i in range(num_classes):\n",
    "        y_true = batch_label[:,i].detach().cpu().numpy()\n",
    "        y_score = batch_pred[:,i].detach().cpu().numpy()\n",
    "        ap = ClassifierEvalBinary.compute_ap(y_true,y_score)\n",
    "        ap_list.append(ap)\n",
    "        pathname = \"./ap_curve/\"+class_name[i]+\".png\"\n",
    "        ceb = ClassifierEvalBinary()\n",
    "        ceb.draw_pr_curve(y_true,y_score,pathname,class_name[i])\n",
    "    return np.array(ap_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model,test_loader,criterion,device,accuracy_th,class_name):\n",
    "    test_loss = 0.0\n",
    "    test_precision = 0.0\n",
    "    test_recall = 0.0\n",
    "    model.eval()   #可以屏蔽BN层和dropout\n",
    "    flag = 0\n",
    "    all_pred = []\n",
    "    for data,target in test_loader:\n",
    "        if device.type==\"cuda\":\n",
    "            data,target = data.cuda(),target.cuda()\n",
    "        with torch.no_grad():\n",
    "            output = model(data)\n",
    "            output = torch.sigmoid(output)\n",
    "            loss = criterion(output,target)\n",
    "            test_loss += loss\n",
    "            precision, recall = calculate_acuracy_mode_one(output,target,accuracy_th) \n",
    "            test_precision += precision\n",
    "            test_recall += recall \n",
    "            if flag==0:\n",
    "                all_pred = output\n",
    "                all_true = target\n",
    "                flag=1\n",
    "            else:\n",
    "                all_pred = torch.cat((all_pred,output))\n",
    "                all_true = torch.cat((all_true,target))\n",
    "    ap = cal_Ap_Adraw(all_pred,all_true,class_name)\n",
    "    test_loss = test_loss/len(test_loader)\n",
    "    test_precision = test_precision/len(test_loader)\n",
    "    test_recall = test_recall/len(test_loader)\n",
    "    print(f\"ap_list is {ap} \\n loss : {test_loss:.4f} - precision: {test_precision:.4f} - recall: {test_recall:.4f}\\n\")\n",
    "    return all_pred.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = am._all_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result = test_model(model,test_loader,criterion,device,0.5,class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),\"./models/deit_multilabel.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create json\n",
    "#\n",
    "# test_result = []\n",
    "# for batch in output_test:\n",
    "#     batch_result = torch.softmax(batch,dim =  -1)\n",
    "#     test_result += batch_result.tolist()\n",
    "# print(len(test_result))    \n",
    "record_list = list()\n",
    "class_dict = test_data.class_dict\n",
    "am = AnnotationManager(class_dict)\n",
    "am.setup_distribution_type(\n",
    "#     distribution_classes = ['0','1','2','3','4','5','6','7','8','9','A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z'],\n",
    "    distribution_classes = am._all_classes,\n",
    "    distribution_type = 'multilabel'\n",
    ")\n",
    "for i,record in enumerate(test_data):\n",
    "#     dist = [0.3, 0.7]  # dist is the output of your model\n",
    "    dist = test_result[i]\n",
    "    instance = am.create_instance(dist)\n",
    "    record_list.append(\n",
    "        {\n",
    "            'info': record['info'],\n",
    "            'instances': [instance]\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "data_out = DataManager(record_list, class_dict)\n",
    "data_out.save('./jsons/deit_test_pred.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
