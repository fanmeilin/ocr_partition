{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "374d22d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets,transforms,models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b58eaf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "# import pytesseract as tess\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcc561f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba7673e",
   "metadata": {},
   "source": [
    "### 参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f83af2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5 # 模型训练5轮\n",
    "log_interval = 30 #控制打印频率的，设n = 30*batch_size，即n张图后打印一次进度\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # 根据设备是否支持GPU来选择硬件 \n",
    "size = 32 # 对输入图片进行处理，拉伸为32*32的图片，这是为了复刻手写数字识别的神经网络，其输入为32*32的灰度图像\n",
    "learn_rate = 0.03 # 学习率\n",
    "momentum = 0.1  # 动量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "badbaad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "读取文件夹下所有图片，将其二值化\n",
    "高斯核去掉噪音，然后使用OTSU算法二值化，再写入文件夹中\n",
    "输入：需要处理的图像list\n",
    "输出：二值化之后的图像list\n",
    "'''\n",
    "def binary_img(images):\n",
    "    Gimg_list = []\n",
    "    for i in range(len(images)):\n",
    "        img = images[i]\n",
    "        blur = cv.GaussianBlur(img,(5,5),0)\n",
    "        ret,thImg = cv.threshold(blur,0,255,cv.THRESH_BINARY+cv.THRESH_OTSU)  #修改THRESH_BINARY\n",
    "        Gimg_list.append(thImg) \n",
    "    return Gimg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c05a186",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "读取文件夹下的所有文件及图片，以灰度图的形式读取并resize到指定大小并且进行norm\n",
    "输入：input_dir：读取的文件夹，可使用模糊匹配\n",
    "输出：图像列表，图片的路径列表\n",
    "'''\n",
    "def readImgAPathWithNorm(input_dir,imgsize=32,Rmap=0):\n",
    "    glob_dir = input_dir + '*.png'\n",
    "    paths = [path for path in glob.glob(glob_dir)]\n",
    "    if Rmap==0:\n",
    "        images = [cv.resize(cv.imread(file,0),(imgsize,imgsize)) for file in paths] #通过通配符读取图像文件并且进行resize\n",
    "    else:\n",
    "        images = [cv.resize(cv.imread(file),(imgsize,imgsize)) for file in paths] #通过通配符读取图像文件并且进行resize\n",
    "    images = binary_img(images)\n",
    "    labels = [name.split(os.path.sep)[-2] for name in paths] #读取对应的路径\n",
    "    images = np.array(images)/255 #将一张图归一化\n",
    "    return images,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96957742",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "读取文件夹下所有图片，将其二值化(不去噪)\n",
    "使用OTSU算法二值化，再写入文件夹中\n",
    "输入：需要处理的图像list\n",
    "输出：二值化之后的图像list\n",
    "'''\n",
    "def binary_img_noBlur(images):\n",
    "    Gimg_list = []\n",
    "    for i in range(len(images)):\n",
    "        img = images[i]\n",
    "        ret,thImg = cv.threshold(img,0,255,cv.THRESH_BINARY+cv.THRESH_OTSU)  #修改THRESH_BINARY\n",
    "        Gimg_list.append(thImg) \n",
    "    return Gimg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cae449b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "读取文件夹下的所有文件及图片，以灰度图的形式读取并resize到指定大小并且进行norm\n",
    "输入：input_dir：读取的文件夹，可使用模糊匹配\n",
    "输出：图像列表，图片标签\n",
    "'''\n",
    "def readImgAPathWithNorm_noBlur(input_dir,imgsize=32,Rmap=0):\n",
    "    glob_dir = input_dir + '*.png'\n",
    "    paths = [path for path in glob.glob(glob_dir)]\n",
    "    if Rmap==0:\n",
    "        images = [cv.resize(cv.imread(file,0),(imgsize,imgsize)) for file in paths] #通过通配符读取图像文件并且进行resize\n",
    "    else:\n",
    "        images = [cv.resize(cv.imread(file),(imgsize,imgsize)) for file in paths] #通过通配符读取图像文件并且进行resize\n",
    "    images = binary_img_noBlur(images)\n",
    "    labels = [name.split(os.path.sep)[-2] for name in paths] #读取对应的路径\n",
    "    images = np.array(images)/255 #将一张图归一化\n",
    "    return images,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6824c6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "显示图片\n",
    "输入：图片矩阵，画布大小：元组（宽，高）\n",
    "'''\n",
    "def showImg(img,figsize=(4,4),cmap = \"gray\"):\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img,cmap = cmap)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5db81b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_dir = \"./result/temp_data/?/\"\n",
    "test_images,test_labels = readImgAPathWithNorm(test_input_dir)\n",
    "# images_divert = [cv.bitwise_not(item) for item in test_images]  #反转图像黑白转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4ceef85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAADnElEQVR4nO3dwU7CUBBAUWr8/1+uSxKlDWCBC3POUjeIuZnkDa8s67qegJ6vV78A4DJxQpQ4IUqcECVOiPre++WyLI5y4cHWdV0u/dzkhChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6I2r2VwvUmPotpWS5epuAgJidEiROixAlR4oQocUKU09obTDyR3XPv++GU9zomJ0SJE6LECVHihChxQpQ4Icoq5Rfrksfbe4+tWc5MTogSJ0SJE6LECVHihChxQtTIVYp1SdfW/2biisXkhChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IGnkr5R08+xaGmzo9JidEiROixAlR4oQocUKU09oXqzwbZ+t1VE5xJ36Fg8kJUeKEKHFClDghSpwQJU6Iskp5gk896uexTE6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihKiRt1L2bolUHmgFJidEiROixAlR4oQocUKUOCFq5Cplj4dxUWFyQpQ4IUqcECVOiBInRIkToqxSOJ1O/ds4E1dcJidEiROixAlR4oQocUKU09o3VD9Z5RgmJ0SJE6LECVHihChxQpQ4Icoq5QmsPq438QPuW0xOiBInRIkTosQJUeKEKHFClFXKDaxEjmFdch2TE6LECVHihChxQpQ4IUqcEGWV8ot1yTGsS/7P5IQocUKUOCFKnBAlTogSJ0SNXKVYl/xl9dFjckKUOCFKnBAlTogSJ0SNPK19d05WZzA5IUqcECVOiBInRIkTosQJUVYpUdYlmJwQJU6IEidEiROixAlR4oQoq5QXszJhi8kJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBDlVsqLbX3LttsqmJwQJU6IEidEiROixAlRTmujtk5xP51T6jOTE6LECVHihChxQpQ4IUqcEGWVQoqLAGcmJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oSokQ/42ntY1NTvKKmY+CCvLSYnRIkTosQJUeKEKHFClDghauQqZY81yzGsRP7P5IQocUKUOCFKnBAlTohyWvthnJJ+DpMTosQJUeKEKHFClDghSpwQlVml3Puh8omrg4l/80QmJ0SJE6LECVHihChxQpQ4IWrxXBxoMjkhSpwQJU6IEidEiROixAlRP5RpUQ0FC8tmAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "showImg(test_images[500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eadd44f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_dir = \"./result/temp_data/?/\"\n",
    "test_images,test_labels = readImgAPathWithNorm(test_input_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "954c4e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_dir = \"./result/augment_data/augment_mask_Gaussion/?/\"\n",
    "train_images,train_labels = readImgAPathWithNorm_noBlur(train_input_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6648aaea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAADaElEQVR4nO3dwW6kMBQAQRzl/3+ZnCPNoIgA05iq4+5l99B6kt/YjHVdF6Dn69P/AOA1cUKUOCFKnBAlToj63vrLMYajXDjZuq7j1Z+bnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEbb4hxDHu/Kr+GC+ft+ECJidEiROixAlR4oQocUKUOCHKKuUgd16XbDnj/2U98zcmJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQoD3zd0N4HsmZ9hGxWJidEiROixAlR4oQocUKU09oH2TrldZLbY3JClDghSpwQJU6IEidEiROirFKifP0ZkxOixAlR4oQocUKUOCFKnBBllfIgbp7ci8kJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBDlVspBfIfkNw+U/Z/JCVHihChxQpQ4IUqcECVOiLJKuYC1AnuYnBAlTogSJ0SJE6LECVFOayfzxB/Zz8rkhChxQpQ4IUqcECVOiBInRFmlsJsf9J/L5IQocUKUOCFKnBAlTogSJ0RZpdyQmyfPYHJClDghSpwQJU6IEidEiROirFKirEswOSFKnBAlTogSJ0SJE6LECVFWKSzL4rGuIpMTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChvCH2Yzy7wjskJUeKEKHFClDghSpwQJU6Iskp5EJ9cuBeTE6LECVHihChxQpQ4IUqcEGWVcgE3T9jD5IQocUKUOCFKnBAlTohyWnuQyomsH7fPw+SEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTohyK2UybsfMw+SEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTohyK+UgW7cwKjdFuBeTE6LECVHihChxQpQ4IUqcEGWV8mF7HsLau5o5et3jEa9zmZwQJU6IEidEiROixAlRTmsvcPSp5hmnpE5ee0xOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oSo4VMB0GRyQpQ4IUqcECVOiBInRIkTon4AOTM+/KqyBEoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "showImg(train_images[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad36efc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, val_x, train_y, val_y = train_test_split(train_images, train_labels, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5916b851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1620, 32, 32), (180, 32, 32))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape,val_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "354bb0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([transforms.RandomRotation(5),\n",
    "                                       transforms.Resize(32),\n",
    "                                       transforms.ToTensor(), # 归一化  对图像进行张量化，以便神经网络处理\n",
    "                                       transforms.Normalize((0.5,0.5,0.5),\n",
    "                                                            (0.5,0.5,0.5)) #变换到【-1 ，1】\n",
    "                                      ])\n",
    "\n",
    "\n",
    "test_valid_transforms = transforms.Compose([\n",
    "                                       transforms.Resize(32),\n",
    "                                       transforms.ToTensor(), #归一化  对图像进行张量化，以便神经网络处理\n",
    "                                       transforms.Normalize((0.5,0.5,0.5),\n",
    "                                                            (0.5,0.5,0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad40c93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"./result/augment_data/temp_train/\"\n",
    "\n",
    "# 使用预处理格式加载图像\n",
    "train_data = datasets.ImageFolder(train_dir,transform = train_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "74e068df",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = \"./result/temp_data/\"\n",
    "test_data = datasets.ImageFolder(test_dir,transform = test_valid_transforms)\n",
    "# valid_data = datasets.ImageFolder(valid_dir,transform = test_valid_transforms)\n",
    "\n",
    "# 创建三个加载器，分别为训练，验证，测试，将训练集的batch大小设为64，即每次加载器向网络输送64张图片，随机打乱\n",
    "trainloader = torch.utils.data.DataLoader(train_data,batch_size = 16,shuffle = True)\n",
    "testloader = torch.utils.data.DataLoader(test_data,batch_size = 16)\n",
    "# validloader = torch.utils.data.DataLoader(valid_data,batch_size = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e84fa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = (\"0\",\"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "25a58d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    \"\"\"\n",
    "    展示图片\n",
    "    img:图片数据\n",
    "    \"\"\"\n",
    "    img = img / 2 + 0.5  # 反标准化\n",
    "    npimg = img.numpy()  # 将数据转换成numpy格式\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0))) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f217ee9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 随机获取部分训练数据\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bda987",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d03b7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 显示图像\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# 打印标签\n",
    "print(\" \".join('%5s' % classes[labels[j]] for j in range(4))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20cc77c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-ddad152b9f32>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#2个卷积层的神经网络\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mConvNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConvNet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         self.layer1 = nn.Sequential(\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "#2个卷积层的神经网络\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2),   #输入1通道，输出16通道，其实代表卷积核的个数为16\n",
    "            nn.BatchNorm2d(16),                                     #输入1通道，输出16通道，其实代表卷积核的个数为16\n",
    "            nn.ReLU(),                                              #激励函数处理\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))                  #最大池化，降采样   2x2 步长为2\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.fc = nn.Linear(7*7*32, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)    #将输出7*7*32拉成一个张量，size(0)，返回行数，view（行数，-1），reshape成多少行数，列数模糊控制不管。\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "model = ConvNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01f2fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "#训练模型\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # 前向传播\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # 反向传播和优化\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "\n",
    "# 测试模型\n",
    "model.eval()    #把模型设置成验证模式\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)  ##data是一个以两个张量为元素的列表\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))\n",
    "\n",
    "# 保存模型\n",
    "torch.save(model.state_dict(), 'model.pkl')\n",
    "#\n",
    "X_test, y_test = next(iter(test_loader))\n",
    "inputs = Variable(X_test)\n",
    "pred = model(inputs)\n",
    "_, pred = torch.max(pred, 1)\n",
    "\n",
    "print(\"Predict Label is:\", (i for i in pred))\n",
    "print(\"Real Label is :\", [i for i in y_test])\n",
    "\n",
    "img = torchvision.utils.make_grid(X_test)\n",
    "img = img.numpy().transpose(1, 2, 0)\n",
    "\n",
    "std = [0.5, 0.5, 0.5]\n",
    "mean = [0.5, 0.5, 0.5]\n",
    "img = img * std + mean\n",
    "cv2.imshow('win', img)\n",
    "key_pressed = cv2.waitKey(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
