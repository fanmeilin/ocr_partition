{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets,transforms,models\n",
    "import torchvision\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "# import pytesseract as tess\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 传统形式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "读取文件夹下所有图片，将其二值化\n",
    "高斯核去掉噪音，然后使用OTSU算法二值化，再写入文件夹中\n",
    "输入：需要处理的图像list\n",
    "输出：二值化之后的图像list\n",
    "'''\n",
    "def binary_img(images):\n",
    "    Gimg_list = []\n",
    "    for i in range(len(images)):\n",
    "        img = images[i]\n",
    "        blur = cv.GaussianBlur(img,(5,5),0)\n",
    "        ret,thImg = cv.threshold(blur,0,255,cv.THRESH_BINARY+cv.THRESH_OTSU)  #修改THRESH_BINARY\n",
    "        Gimg_list.append(thImg) \n",
    "    return Gimg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "读取文件夹下的所有文件及图片，以灰度图的形式读取并resize到指定大小并且进行norm\n",
    "输入：input_dir：读取的文件夹，可使用模糊匹配\n",
    "输出：图像列表，图片的路径列表\n",
    "'''\n",
    "def readImgAPathWithNorm(input_dir,imgsize=32,Rmap=0):\n",
    "    glob_dir = input_dir + '*.png'\n",
    "    paths = [path for path in glob.glob(glob_dir)]\n",
    "    if Rmap==0:\n",
    "        images = [cv.resize(cv.imread(file,0),(imgsize,imgsize)) for file in paths] #通过通配符读取图像文件并且进行resize\n",
    "    else:\n",
    "        images = [cv.resize(cv.imread(file),(imgsize,imgsize)) for file in paths] #通过通配符读取图像文件并且进行resize\n",
    "    images = binary_img(images)\n",
    "    labels = [name.split(os.path.sep)[-2] for name in paths] #读取对应的路径\n",
    "    images = np.array(images)/255 #将一张图归一化\n",
    "    return images,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "读取文件夹下所有图片，将其二值化(不去噪)\n",
    "使用OTSU算法二值化，再写入文件夹中\n",
    "输入：需要处理的图像list\n",
    "输出：二值化之后的图像list\n",
    "'''\n",
    "def binary_img_noBlur(images):\n",
    "    Gimg_list = []\n",
    "    for i in range(len(images)):\n",
    "        img = images[i]\n",
    "        ret,thImg = cv.threshold(img,0,255,cv.THRESH_BINARY+cv.THRESH_OTSU)  #修改THRESH_BINARY\n",
    "        Gimg_list.append(thImg) \n",
    "    return Gimg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "读取文件夹下的所有文件及图片，以灰度图的形式读取并resize到指定大小并且进行norm\n",
    "输入：input_dir：读取的文件夹，可使用模糊匹配\n",
    "输出：图像列表，图片标签\n",
    "'''\n",
    "def readImgAPathWithNorm_noBlur(input_dir,imgsize=32,Rmap=0):\n",
    "    glob_dir = input_dir + '*.png'\n",
    "    paths = [path for path in glob.glob(glob_dir)]\n",
    "    if Rmap==0:\n",
    "        images = [cv.resize(cv.imread(file,0),(imgsize,imgsize)) for file in paths] #通过通配符读取图像文件并且进行resize\n",
    "    else:\n",
    "        images = [cv.resize(cv.imread(file),(imgsize,imgsize)) for file in paths] #通过通配符读取图像文件并且进行resize\n",
    "    images = binary_img_noBlur(images)\n",
    "    labels = [name.split(os.path.sep)[-2] for name in paths] #读取对应的路径\n",
    "    images = np.array(images)/255 #将一张图归一化\n",
    "    return images,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "显示图片\n",
    "输入：图片矩阵，画布大小：元组（宽，高）\n",
    "'''\n",
    "def showImg(img,figsize=(4,4),cmap = \"gray\"):\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img,cmap = cmap)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_dir = \"../result/temp_data/?/\"\n",
    "test_images,test_labels = readImgAPathWithNorm(test_input_dir)\n",
    "# images_divert = [cv.bitwise_not(item) for item in test_images]  #反转图像黑白转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAADnElEQVR4nO3dwU7CUBBAUWr8/1+uSxKlDWCBC3POUjeIuZnkDa8s67qegJ6vV78A4DJxQpQ4IUqcECVOiPre++WyLI5y4cHWdV0u/dzkhChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6I2r2VwvUmPotpWS5epuAgJidEiROixAlR4oQocUKU09obTDyR3XPv++GU9zomJ0SJE6LECVHihChxQpQ4Icoq5Rfrksfbe4+tWc5MTogSJ0SJE6LECVHihChxQtTIVYp1SdfW/2biisXkhChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IGnkr5R08+xaGmzo9JidEiROixAlR4oQocUKU09oXqzwbZ+t1VE5xJ36Fg8kJUeKEKHFClDghSpwQJU6Iskp5gk896uexTE6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihKiRt1L2bolUHmgFJidEiROixAlR4oQocUKUOCFq5Cplj4dxUWFyQpQ4IUqcECVOiBInRIkToqxSOJ1O/ds4E1dcJidEiROixAlR4oQocUKU09o3VD9Z5RgmJ0SJE6LECVHihChxQpQ4Icoq5QmsPq438QPuW0xOiBInRIkTosQJUeKEKHFClFXKDaxEjmFdch2TE6LECVHihChxQpQ4IUqcEGWV8ot1yTGsS/7P5IQocUKUOCFKnBAlTogSJ0SNXKVYl/xl9dFjckKUOCFKnBAlTogSJ0SNPK19d05WZzA5IUqcECVOiBInRIkTosQJUVYpUdYlmJwQJU6IEidEiROixAlR4oQoq5QXszJhi8kJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBDlVsqLbX3LttsqmJwQJU6IEidEiROixAlRTmujtk5xP51T6jOTE6LECVHihChxQpQ4IUqcEGWVQoqLAGcmJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oSokQ/42ntY1NTvKKmY+CCvLSYnRIkTosQJUeKEKHFClDghauQqZY81yzGsRP7P5IQocUKUOCFKnBAlTohyWvthnJJ+DpMTosQJUeKEKHFClDghSpwQlVml3Puh8omrg4l/80QmJ0SJE6LECVHihChxQpQ4IWrxXBxoMjkhSpwQJU6IEidEiROixAlRP5RpUQ0FC8tmAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "showImg(test_images[500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_dir = \"../result/temp_data/?/\"\n",
    "test_images,test_labels = readImgAPathWithNorm(test_input_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_dir = \"../result/augment_data/augment_mask_Gaussion/?/\"\n",
    "train_images,train_labels = readImgAPathWithNorm_noBlur(train_input_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAADvklEQVR4nO3dwWqkUBBA0XaY//9lZzkQOo+OtJ1bes4ygSDCpeBV1G3f9wfQ8+e3LwB4TpwQJU6IEidEiROi/q5+uW2bo1w42b7v27Ofm5wQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRC3fIcR9fPfm/217+nobPsDkhChxQpQ4IUqcECVOiBInRFmlRFU+aly5jjuudExOiBInRIkTosQJUeKEKHFClFXKL6usKurOuE/19YzJCVHihChxQpQ4IUqcECVOiLJK+QDrEo4wOSFKnBAlTogSJ0SJE6LECVFWKW9yx3XJ6qmOCfdjdY2FJ1ZMTogSJ0SJE6LECVHihCintTdSOIHkdSYnRIkTosQJUeKEKHFClDghyirlByr/zD1hJTL9n+ILTE6IEidEiROixAlR4oQocUKUVQq3VV9JmZwQJU6IEidEiROixAlR4oQoq5SLqX9igNeZnBAlTogSJ0SJE6LECVHihCirlIGOviDrk2uWyku8Jq+PTE6IEidEiROixAlR4oQocUKUVQpLlZXIHZmcECVOiBInRIkTosQJUU5reTweTmWLTE6IEidEiROixAlR4oQocUKUVcqbrN5VY01xrsnvCVoxOSFKnBAlTogSJ0SJE6LECVFWKT9w9Mj+qp86OMNV1yJHmJwQJU6IEidEiROixAlR4oQoq5SoK69LeI3JCVHihChxQpQ4IUqcECVOiLJK+YCrrkU8QXIukxOixAlR4oQocUKUOCHKae2bTD+RdfLaY3JClDghSpwQJU6IEidEiROirFK+sBKhwuSEKHFClDghSpwQJU6IEidE3XKVYl3CBCYnRIkTosQJUeKEKHFClDgh6tKrlAkrE2sRvmNyQpQ4IUqcECVOiBInRIkTosavUqxL3uO7+7i69qP3fsL9KDA5IUqcECVOiBInRIkTokac1k44kV2ZfP1nXPvqbzrJ/c/khChxQpQ4IUqcECVOiBInRGVWKZPXDXAGkxOixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4ISrzVMoZr/2nyUu8XmNyQpQ4IUqcECVOiBInRIkTojKrlBVrFu7I5IQocUKUOCFKnBAlTogSJ0SNWKWsHHnCwWfPmcDkhChxQpQ4IUqcECVOiBp/WnuEE1kmMDkhSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6I2nzOAJpMTosQJUeKEKHFClDghSpwQ9Q+TjHfzzHv2uQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "showImg(train_images[110])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, val_x, train_y, val_y = train_test_split(train_images, train_labels, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1620, 32, 32), (180, 32, 32))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape,val_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用pytorch的形式读取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 三通道"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([transforms.RandomRotation(5),\n",
    "                                       transforms.Resize(32),\n",
    "                                       transforms.ToTensor(), # 归一化  对图像进行张量化，以便神经网络处理\n",
    "                                       transforms.Normalize((0.5,0.5,0.5),\n",
    "                                                            (0.5,0.5,0.5)) #变换到【-1 ，1】\n",
    "                                      ])\n",
    "\n",
    "\n",
    "test_valid_transforms = transforms.Compose([\n",
    "                                       transforms.Resize(32),\n",
    "                                       transforms.ToTensor(), #归一化  对图像进行张量化，以便神经网络处理\n",
    "                                       transforms.Normalize((0.5,0.5,0.5),\n",
    "                                                            (0.5,0.5,0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 灰度图形式读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "                                       transforms.Grayscale(),\n",
    "                                       transforms.RandomRotation(5),\n",
    "                                       transforms.Resize(32),\n",
    "                                       transforms.ToTensor(), # 归一化  对图像进行张量化，以便神经网络处理\n",
    "                                       transforms.Normalize([0.5],[0.5]) #变换到【-1 ，1】\n",
    "                                      ])\n",
    "\n",
    "\n",
    "test_valid_transforms = transforms.Compose([\n",
    "                                       transforms.Grayscale(),\n",
    "                                       transforms.Resize(32),\n",
    "                                       transforms.ToTensor(), #归一化  对图像进行张量化，以便神经网络处理\n",
    "                                       transforms.Normalize([0.5],[0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 分为test、train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 64\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"../result/augment_data/train/\"\n",
    "test_dir = \"../result/augment_data/test/\"\n",
    "test_data = datasets.ImageFolder(test_dir,transform = test_valid_transforms)\n",
    "train_data = datasets.ImageFolder(train_dir,transform = train_transforms)\n",
    "# valid_data = datasets.ImageFolder(valid_dir,transform = test_valid_transforms)\n",
    "# 使用预处理格式加载图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建三个加载器，分别为训练，验证，测试，将训练集的batch大小设为64，即每次加载器向网络输送64张图片，随机打乱\n",
    "trainloader = torch.utils.data.DataLoader(train_data,batch_size = batch_size,shuffle = True,num_workers=4)\n",
    "testloader = torch.utils.data.DataLoader(test_data,batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 560)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(len(trainloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 预览"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    \"\"\"\n",
    "    展示图片\n",
    "    img:图片数据\n",
    "    \"\"\"\n",
    "#     img = img / 2 + 0.5  # 反标准化\n",
    "    npimg = img.numpy()  # 将数据转换成numpy格式\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0))) \n",
    "    \n",
    "# 随机获取部分训练数据\n",
    "dataiter = iter(trainloader) #迭代器\n",
    "images, labels = dataiter.next() #每一条数据大小为16\n",
    "classes = train_data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    3     6     T     Q     0     P     Y     G\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAB4CAYAAADrPanmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAxIUlEQVR4nO2dd1wU197/P2eXzgIqIiIaEWPBWCNiNNgLxppiNEZFTKIkluRGjT9Fb0w01jwmmucq6vUao7FjUK8pYu8FwRIbiiiCqAhSF3bZcn5/wO7DsjNbZ7bgvF+v89rdmTPnfM45M989cyqhlEJAQEBAwPkQ2VuAgICAgIBlCAZcQEBAwEkRDLiAgICAkyIYcAEBAQEnRTDgAgICAk6KYMAFBAQEnBSrDDghZBAhJI0Qkk4ImcOVKAEBAQEB4xBLx4ETQsQA7gIYACAbQDKAMZTSW9zJExAQEBBgw5oaeASAdEppBqW0AsBOACO4kSUgICAgYAwXK64NBpBV7Xc2gK6GLiCECNM+BQQEBMwnj1IaUPOgNQacMBzTM9CEkMkAJlsRj4CAgMDLTibTQWsMeDaAJtV+NwaQU9MTpXQDgA2AUAMXEBAQ4BJr2sCTAbQghDQjhLgB+ADAAW5kCQgICAgYw+IaOKVUSQiZBuAQADGATZTSm5wpExAQEBAwiMXDCC2KTGhCERAQELCEFEppeM2DwkxMAYtJSUnBkCFD7C3DYUlMTMSMGTPsqmHv3r2YPXs2AMDDwwNZWVl45ZVXAADDhw9HdnY2srOzIZFIkJCQoPXrzCxbtgzZ2dm4cuWKvaXwjjWdmHZh48aN8PX1ZT2fmpqKZcuW2VCRYTZs2IA6deoY9FNaWoqPPvqINw3r169H3bp1OQ83LCwMnp6enIdrSrzffvutSX5v376NBQsW8KxIny1btiAyMhItWrTAG2+8AblcjvHjx9skbn9/f8THxwMAevTogbCwMISHh0MsFiM4OBjx8fGQSqVo0qQJgoODQSnV6m3Tpg3Cw3UremvXrsWJEyc41xkbG4t+/foxnrt//z7mzp2rd7xOnTrYsGGDwXBff/11BAcHQyTit366adMmSCQSs6/LzMzEV199xY0ISqnNHCqHGVrk3N3daUxMDC0uLqaGuHr1Kh0zZozF8XDl3NzcaExMDC0sLDSol1JKS0tLaUxMDPXw8OBUg6urK42JiaEFBQVGNVjKyJEjbZKf48aNozExMTQmJoYuXbrUZH1paWl07NixNtEYGhpKY2Ji6MSJE2l5ebmODplMRidOnEglEgnvOho3bsxpGW/cuJH26tWLE21isZhOmDCBxsTE0JMnT7LGmZyczHh9UFCQybpzcnI4z9smTZpo78OSkhKL8vPRo0c0OjqaVjUpm+ouUyabynSQL2dppnl6etLOnTtTtVptUgbl5+fT0NBQKhKJbPLgMunt1KmTyXo1REREUC8vL850+Pn5ma3BXKZOnUrr16/PSz5KJBIaGhpKmzdvTsvKyizWWFJSQkNDQ6lYLOatzAMCAuiXX35pVEuPHj1oaGgoDQgI4EWHt7c3ffPNNy3OKzZ27tzJiT4PDw+qVCoNxlVQUED37dvHeL0pBjw3N5emp6fT8+fPc5q39evXp5MnT+YkP+VyOXVxcTEnfuc14IMHD7Yokxo0aMDbA2vIRUVFWaSXUkrffvttznSwGXC1Wk1VKpWOY8OYX5VKRf/9739znoeEEDpx4kSL85GJJk2a8FbmW7duNUvLtm3bzK2BmZRnH3zwAad5pmHXrl2c6PXw8KAVFRUGKxbLly9njathw4ba+5AtjNjYWF7yNj4+njE+pmfE2LMlGHATKC0tpYMGDeLtoWVyS5cutaq2aAsDrlQqqb+/P/X29qbe3t4G87em37feekvn/Lhx46i7uzvn+fjzzz/rNUNYiyMZ8IqKCnrr1i1ONaxbt47zPNOgUChoWloaJzq9vb1peno6a1xyuZyeOnWK8VpCiPZePHbsGOP1MpmMbtu2jdO8TUlJoRUVFYzx/fTTT1pNNV1ISAhrGrkw4LV6FIq3tzfEYrHN4vv5558xfvx4u3TsmUpWVhZ69uyJFy9eQCqVQiqVQiaTGbxG408qleLcuXOIiorS/CFDJpNBLpdzqvG3337DkCFD4OHhwWm4e/fuRf/+/TkN01JcXV3h7e3NaZju7u44c+YM3n33XU7DBQAXFxfO9EqlUowaNQqRkZGYP3++3nk3Nzd06tQJR48e1euIpJRq70WVSsUY/k8//YRFixZxotXV1RUnTpxA69at4erqqqNj8ODBiIyMxA8//KDzjFR3ZWVlnOhgw+lGoQDAjh07kJ6ernc8KioKERERdlBUSceOHREcHMx6Pi8vTzs6YNKkSWjYsKGtpCEhIQG3b99Gfn4+zp07pz3et29fjBs3zuRwioqKcPLkSXz33XcAKkd5cIWbmxtmz56Nvn37ws/Pj7NwNXTp0gX169fnPNzp06ejbdu2jOdOnjyJjIwMTJw4Ue+cr68v5s2bhxUrVkChUFit48CBA3BxcUFycjLjeYVCgeXLl2v/fKsze/ZsuLu7Gwzfx8cH8+fPx4oVK1BRUWGV1tTUVABgfQYkEgm6d+8OQpiWXAJmzZqFZs2a6R1fu3Ytdu/ejTt37lilTwMhBG+++SZcXP7PVJaWluLHH3/EiRMnUF5ebvB6qVSKRYsWYdasWfxU7Jiq5Xw5WPj6Uv0VPyUlhXbv3p3R36pVq/ReVYYMGcLba3N1Fx4eTtPS0hhflyil9OnTpzodQVu3bqU5OTl6/rhsQpFIJPTChQv0woULtE+fPox+li1bxqq5vLycnjt3jrq5ufGefz4+PrR3794md7oqlUp68eJFeuHCBZqXl2fSNZRS+sEHH3Cu/eHDhzpxqNVqmpycTC9cuEA/+eQT2q1bN1Y9KpWK05Ep9erVo0OHDmWMSyqVsrYNHzt2THuv3Lhxg1WvWq2mvr6+nOl97733GOMpLS2lp06dYh2IwDayqmXLlpxp8/Lyom+++SZVKBTa8F+8eEH/+OMPs8NKSkrS0fxStYFHRUVRqVRKpVIp9ff3Z/VnLwPu4uJCZTIZ4w1VVlZGpVIpXb16td51S5Ys0aZL44YNG8a7Xo1zd3enK1euZNRNKaV37961iQ4XFxc6cOBAVh3VqaiooFKplD579kx7/S+//ELlcrlJ13NtwD09PWlmZqZOHCqVinp7e2v9dO3alZaVlen9OalUKlpaWqrj11o3evRo1rQbMuDVXUREBGsYtjLgKSkprMNqPT09dYyhSqXSPj8tWrTgTFuHDh30dLGNjjHF7du3j8rlcqpSqWhhYeHLY8ABUJFIZHRYoCMa8KCgICoSiRgfHEKINl2mpI9rd/HiRYMjUGxlwBcuXGh0aJmG+fPn6+UVIYTGxMSYdD2XBtzb25sqFApGw1zTKPv4+OjldWZmJudlXlsMuFqtpqWlpXpDPxs2bEiVSqVOnqekpPDy/HBtwAkh9Msvv6RXr161RKtzd2Kq1Wqo1WrW8//9738RHR1tQ0WmcebMGdy+fRt37txBWlqajps4caI2XcbSxwcikYh1ttqePXswcOBAm+kwpbP5/fffx5o1a/TyilKKvXv3om/fvnzKZEQkErG202ro1KkTUlNTGf3ZusydBUKI3j0xcOBAnD17FmKxWCcvKaWcPz8fffQR9u/fz1l4QKXOn3/+GcOHD+dMq1N2Ympo1KgRvv76awBA9+7d9aaLz5w5E3///TevGho2bIiFCxfqdHJUJzQ0lPXaTz75BD4+Pli9ejVf8iymqKgIDx8+tLcMAJVG7osvvsCpU6dQUFDA6KekpMQh9Obn5yMuLk5nZI6HhwdeffVVO6oynbfeeguTJk2ytww9xo4di+joaL3n6dChQ0an1ltC3bp10bRpU87DLSwsRGFhIWfhOa0Bb9asGYYOHYrY2FhWP1u2bEFeXh6vOurUqWPxDd+tWzd4enri7t27+PPPPzlW5hz07NkTLVu2ZD0vlUqRlJSEDRs2GBz50KRJE4cYIqhSqfD06VPGkR7Vyc7ORlJSko1U6dK/f394eXkBqBwGmpSUhMGDB8PFxQXvv/8+3nnnHcbrysvLcejQIU5GzGjIycnBoUOHEBUVpXdOJBJh2LBhUKvViI6O1nsjPHfuHLZv347ffvuNMz2GuHbtGi5evGiTuEyGqV2FLwcO26emTZvG2k6nga8p3tVd69atjeowRn5+Pu86a7qAgAB65coVVk18zK5k0pCSkmIwb9LT000Ka8KECSblNddt4Ex9CDXbwJlGoSQkJBjskLfUGWoDLysrow0bNqQPHjzQHnv8+DFt0KCB0TWGKKU0Ozubl/ugUaNGJpUdpZWjj54+fUqfPn1Ke/Towdu9OXPmTL24P/30U96fCQOOsQ3caWvgzgStqo0Zayu1FWKxGI8ePeJ8oow5iEQiPHz4UFsTfNl477330KVLF15e09nw9PTEkydPdI41atQIz549s5kGa3n27JnBuRYvG0Y7MQkhTQghxwkhtwkhNwkhX1Qdr0cIOUwIuVf1yf16pVZy584dDBgwwN4yEB0dbXCd5Tp16iA3NxcBAXqbTgs4KBEREXj48KHen3JWVhYCAwMhlUrtpEzAWvbs2YNvvvnG3jJMwpQauBLATEppKiHEB0AKIeQwgBgARymlywghcwDMAfD/+JOqy8GDB6FWq7FmzRpWP/7+/nBzc+NNw+DBg42u6zt+/HgcPnwY7u7uuH37NsRiMRISEnSm5YpEIgQEBGDbtm34+uuvceHCBd40m8LSpUuxc+dOu2owh6+++goffvihUX8TJ07EqVOnOInT1dWVcVanWq3mvd/FHpw+fdrkNdj54uzZszYxrH5+fozrfE+ZMgX+/v5YvHixSeF07dqVcamAmmFmZWVZpBMwwYBTSp8AeFL1vYQQchtAMIARAHpXefsFwAnY0IA/fPgQiYmJeO2117THIiMj0b59e1tJQNOmTdG7d2/GczKZDJs2bcL+/ftRUlICAHj06BHEYjHrEKIBAwZg7dq1fMkFUHlzjhs3zuCwvZSUFFy/fp1XHZbw7rvvIjAwUO/4qFGj0LFjR9brKioqsHHjRuzfv591FAtfhIeH87I2ia349ddfUVxcjJSUFBw9etRuOk6cOIFt27bhyJEjdtPQrl07ZGRkmOw/MDAQQ4cONejnypUr2L17N27cuGGRJrPawAkhIQA6AbgIILDKuINS+oQQ0oDlmskAJlukzghPnjzB1KlTtb9XrVqlZ8AbN26MBg0aIDc3l/P4CwsLkZGRwThUUCqV6mhzFBo0aIB//etfrOfT09O1fziOxldffYU33njD7OvkcrnJZUEIQcuWLXH//n0olUqz4ikqKsL9+/d1jg0ZMgSzZs0yya+9efToETw9PSGRSJCZmQkAiIuLs6qGyAUZGRlYu3Yt9uzZY1cdfPDPf/4Tz54949+AE0IkAPYC+AeltNjUDjlK6QYAG6rCoJaINBW1Wg2VSqVTu1y3bh3atm2L6dOncx7fjh07cOXKFU4XdLI3vXr1Qk5Ojr1laKk+ocOSTmBKqVmG2NvbG7du3UJISAir4SKEME6A+u9//2vytmkHDx40axExLlGpVKCUatOhWdVv/PjxiIyMxPDhwy36o+QaSilUKhWioqIYF6/jC5VKBbVazVjGmvuRbSVEW2PSTExCiCsqjfc2Sqlm0OUzQkhQ1fkgANxXcc1k9uzZGDlypL1lCHBISEgISktLUVpaii5duph9/blz5xAUFMSppri4OBw+fJjTMG1J27ZtIZFIEBMTg8ePH0MikUAikeD06dP2lqaDXC6Hn5+fzd9Uhg8fjri4OMZzQ4YMcag3J1NGoRAA/wFwm1L6Q7VTBwBMqPo+AQC3806r8eabbyI5ORnJyckGNwhWKpVWL3NpT6KionjZPNaZEYlE8PDwgIeHh9mb1MbHx+Pjjz82a73ysrIyREREGBxa5+Liwrj06ltvvYUDBw6YpdGWyGQyREREICMjA3K5HL///jsGDx4MuVwOuVwOSik2bdqEmJgYe0vVotFlSxQKBetbm1gsNrrsroaTJ08iPDwc4eHhKCoqYvTz/vvvY/fu3RZrNeWJeBPAeAB9CSFXq9xgAMsADCCE3AMwoOo3L/j5+WkzYsGCBWjVqhVfUXGGl5cXFi9ebNau1deuXeN0mm1NunTpghkzZvAWvjlQSrFgwQJe21dzcnKQlpZm1jVqtRopKSkGKwJHjx7F+vXr9Y77+/vr9MFMnjyZcdf13bt3W/XQWoparcbly5e1aSsoKNBbauLp06ecraVtCq+99hrmzJmjdzw7Oxtff/21Q64VI5FIsHjxYqPrexcVFeHOnTt49913WUfD3bx5E8+fP7dcDNPsHr4cLJyFVHPLr9mzZ9PmzZvr+WvevDmdPXu2jt+///6bfvHFF7zNkDI2EzMwMJAClZux9ujRg/bu3Vtv6dOKigp68uRJWrduXV5nc02aNIlVp0KhoCdPnuRldqAhd+HCBYP5Zw3z58/nTTfbxsEPHz7U+jl9+jSjn7Fjx/Kmi4vVCG3p2FYjZNuV3lZu9OjR9PLly6x5qVar6ZAhQ4w+sw0aNDBwh1IaFhZmqqbaMxNz+fLlaNasGWbOnKndssjLywszZ87EZ599puN3zpw5+P333+0hE0Blp5hEIsGoUaOwatUqRj8lJSXo1auXbYXVoLS01C4aysrKIJfLTX4tdRRUKhVKSkogkUh0OlcJIdq3LqahmqWlpWaPbqmtuLu723U2sCF27dqFO3fu4OrVq4znCSE4ePAg3n77bYPDK815A7cEpzTgABAbG4vu3bujQ4cOAIDz58+jXbt2dlalz7179wA4zjR6R6Nv37747rvvMG/ePHtLMYsLFy6gUaNGKCoq0inbJk2aaNs7mcq8ffv2ePDggc10OjL/+7//i08++cTeMqwiMTHR5m301XGa9cBrQghB69at8eDBAzx48ACtW7e2i5G8f/8+Xn31VdY2U82a2/Y24GvXrsWSJUvsqoGN//mf/8EHH3xgbxlmw/TgaobmsZW5I7bp2gtCCOtz0a5dO9y5c8fsjmsuuXXrFlq1amXwjal6ebM5PnFaAw5UboIbEhKCkJAQxk6CqVOnsr4CcYVCoUBGRgY++ugj7eQHc7hx4wamTJnCgzJdAgICDG7o6+XlhV9++cXgKB++KCwsxIkTJxAbG2vX2oy5yOVyxMTEmDV1/ocffkD37t15VFU7cHd3x6uvvorNmzczzr61BQqFAunp6Zg4caJDzY2ojlM0oeTk5CAxMZF1neKayOVyJCYmYuvWrTaZVUgpxbZt29CuXTu8/fbbJo2S+euvv1BYWIi///4bu3bt4l2jMdzc3BAdHY25c+fyOhKGjWfPnmHLli3o06eP2dd269ZNu6ofrdqdR6lU4ubNm1zL1EGpVGLr1q2IiIjA0KFDERISYtBvQkICANi1VmlvRCIRRo4cCUKIwc1OgMo+hPHjx2PRokV2WzFRrVbj119/RadOnTB8+HCzN+aQyWTYt28fgMpJclzPSXCKUShA5W7bWVlZJu2d+Pz5c7v1XhvaJLg6HTp0sKmuPXv2mKSrUaNGdu39t8StWbOG5ufnU4VCQTMzM6mnp6fNNWzdupUxP4uKimhWVhZNS0uzyQiQYcOG0ZycHD0dMpmM3r171+6jUDw8PEze/1QDlxsVW+OWLFlCnz9/brLusrIyeuXKFZ17JCsriz59+lTrx9pRKE5jwDXu2bNnVK1WG3S5ubl2K+SVK1ca1adWq+1iwE3RFRQUZPcHxRIXHR1N79+/b7f4t2zZwpifCxYssLmWxo0b6+k4f/683csIqDTgmo2gTXWOYsAB0OHDh5usOzExkTGM9u3ba/1Ya8AJtWGbIxdrofj6+oIQgsmTJyMmJoaxPZFSiuLiYmujsggPDw+ThsSVlJTYtEPLy8tLZwlbNoqLi52qHVqDq6srPDw87LYQF1v+ymQys2aCcgEhBL6+vjrHVCoVSktLbaqDDT8/P6SkpGD16tXYsmWLUf+2flYM4eLiAm9vb5P8KhQK7TDn6ohEIvj4+AAwK20plNLwmgedzoBraNy4MYKDgx1vjzoBAQGjdOvWDZmZmQ7bOeiA1C4DLiAgIPASwWjAX97ucAEBAQEnRzDgAgICAk6KYMAFBAQEnBTBgAsICLzU9O3bF8ePH+cl7Hr16uH69et6o4K4QjDgAgICLzW+vr5o3bq1zrHevXsz7mVqLi4uLmjbti1cXNgnvb/77rv4+OOPLQrfZANOCBETQq4QQg5W/a5HCDlMCLlX9VnXIgUCAgICdiQ3N1dvJ6zOnTtj7NixVoddUVGBpKQkKBQKVj99+vTB8OHDLQrfnBr4FwCq7947B8BRSmkLAEerfgs4GZpdyAX4QywW22WRMA0eHh7aiSOW4urqCj8/P44UORbnzp3DmDFjtL81a7xrJgPWrVsXdevWtWjN+sLCQgwaNMjgBLOysjLLJ1mZOAW+MSqNdF8AB6uOpQEIqvoeBCDNFlPpBcetW7ZsGT1y5IjdddRm161bN1pSUmK3dUji4uKsnkr//vvv06ysLLvnpS1cUlIS/f777ykA6ubmRisqKqharaaffvqpPXVZtSPPKgCzAVT/Gw+klD4BAErpE0JIAxPDeunYtGkTBg4cCKBySnOLFi3ssvnyhx9+iBUrVugc8/X1hZubG7Kzs00Op6SkBGFhYVzL05KcnGzWqm1TpkxxmM2EmWYHu7m5wcvLC9nZ2aCU4vPPPwelFHPnzkVERARvWtLS0uDt7Q0fHx94eHiYVcY18fT0RHl5OYfqzGPFihX48MMPkZubi9dff533+D799FOMGTMGhBC4uLhwup5/WFgYDh8+rP09f/58bN682aKwjBpwQshQALmU0hRCSG9zIyCETAYw2XxptYMNGzZg4MCBCA4OBlC5POX27dsxc+ZMi9YPt5QZM2ZgzJgxWh01YTvOBJfLzS5ZskRvic42bdrAy8vL5DDmzp2LcePGITc3F9OnT8eWLVuwcOFC7W5ItkQsFrPmZaNGjQAAs2fPBgBe1rnu3r07/vGPfwAAmjVrprM+izllzMTjx4+tut5SVq9ejaFDhyI4ONhmG6NIJBLOmxbj4uLQsWNH+Pn56ZTF559/jgYNGuhVrkzChGaPpQCyATwE8BRAGYBfITShGHRubm40JiaGFhYWMi41acvVCEePHk2Tk5MZdVhCQUEBZ9q43NQ4NzeXTpw4kcpkMrpw4UKb5nGPHj1oTEwMnTlzpsl6MzMzeSlrvsjOzrbLs5SWlqbVUFBQQGNiYqirqytv8SUlJTGm35omlDFjxtDr16+z5u3+/fuNhWH9crIAeuP/2sC/BzCn6vscACtMuN7qzG3atCkNDQ2loaGhtHHjxna5oYw5T09P2qlTJ6pWq1kLzJbG5fHjx8aeTbOwtQFXq9U0IyODpqena11GRobB/KWU0pUrV/K6PC4hhDZr1oyGhobSxMREs/NRMOCm5W9GRoaODrVaTf38/HiLl82Az58/nwYGBpoVlkgkoqGhobSgoIAxzEePHtH09HS6fv16Y2FxbsD9Udmxea/qs54J11tckBqXm5urTfz169etCovrTiVNmFFRUUYfBlsa8OzsbKPGzhy4NODnz583qk2pVOpt0iCRSKhSqTR67alTp3jLV29vb6pSqQzGr1arWf1kZmZyfg+OGjWKqlQqqlKpjOaNRpup/m1twN3d3alCoWDUXbduXd7iZTPglFK6b98+s8IKDAw0mKfWrgdu1kQeSukJSunQqu/5lNJ+lNIWVZ8vzAnLVL7//nsUFxdrnaF9HY3h4uKC/Px8bViaLa644syZMyguLkZiYiKn4VpLy5YtsX//fnvLYKRv3774/vvvzb6utLQUfn5+dmuXNZWlS5diwIABjOcaN26MoqIik9eXNoW9e/fC19cXfn5+Roemafxq3JkzZzjTwTdZWVno3bu3vWUYZMiQIbh//z6vcTj8TEx3d3dth4JmfKaG0NBQHD9+3OAsp+XLl+P06dM4ffo0Tpw4AT8/P21Ynp6enGgUi8U4duwY2rdvz2m4XFFWVoY5c+Zg+fLlyMrKQs+ePXU2GUhJSUFkZCQiIyPN2qCXC8rLyw1OcgAqF8A/cuQI2rRpo3NcKpXinXfeQWRkJBYvXsx4bfv27bXl36CBbQZKqdVqDBgwAJGRkVi3bh2Sk5PRv39/vYX7RSIRvL29Oe2YU6lUkEqlJo0rViqVkEqlWjdlyhTtfdCvXz8dvUePHjV5T1q+IYTA29sbYrGYl/C//PJL/Otf/7I6HLFYzPrnrFAo0KtXLzx8+NCqOJxiU2M2vL290aNHD8ybNw9r167F8+fP9fy0adMGkZGRvGnw9/fH1KlT0aNHD4N/JPYmLS0Ne/bswZMnT3DmzBksWbJEqzcjIwNnz54FAIO7xxw7dgxnz56FTCbjVNvx48fRpEkTREdHM54nhKB79+6Mk1EuX74MAKybzfr5+WnL/6uvvsLmzZt53ey4sLAQP/30E06ePKnzx3T+/Hne4rSEAwcO4LffftM5duPGDe13FxcXfPfdd5g2bRrq1auHvLw8JCcn20xfUFAQYmNj7bIB9M2bN602rIMGDcKoUaP0jl+8eBFJSUlQqVQ4c+aM1TsNOa7FMRGxWIxvvvkGe/fuZTTgbGRmZiItLc3q+AMCAvDtt99aHY4tSElJQUpKCgBg4cKFZl+flJSE5cuXcy0LR48ehVKpZDXgXDFr1iykpKRwYsAlEgk6d+6srT3fv38feXl5ePr0KRYsWKDnX61W49KlSyCEoHnz5lY1BXLBtWvXkJqaqnOsdevW8PX1RWlpKW7duoUFCxagbdu2CA4O5r0poDpBQUEYMGAAYz46C8OGDWOcin/+/Hl8/fXXnMXj0Abc3d3d5Fqtu7s7xGIxVCqVSf5//PFHrF692hp5rKhUKlRUVDhcUwobIpFIO0245us8pRQymQyUUiiVSnvIMwmlUgmZTAYPDw+bxNehQwed9TMWL16MX3/9lbU5SCaToVu3bgCArVu3Yty4cbaQyco///lPtG7dGtHR0dp8W79+PXr27Ink5GT07NkTMpkM7733ns21jR8/3qSKgsY+cH1furm5mbR/rCPg0G3gly5dQmxsrEl+L168iClTpvCsyDSOHj2KV155xWk2B+7VqxdKSkpQUlKiNwNSrVYjICAAPj4++OGHH+yk0Djbt29H27Zt7Rb/xo0bsXHjRrvFbwkjR47EnTt3AAA5OTno0aMHACA8PBzPnz+3S/OFORw4cACLFi3iJVy2PhVHwyFr4C4uLrh27RqaN29u8k0kFov1ao8XLlzAa6+9xodEVpYuXYo1a9bgxYsXaNWqFc6dO2f312VjEEIMdgipVCqH2RWcDUqpXTWKRCKHN3g1IYSgUaNGSEtLg5+fn/b5IYQ4RFrkcjk6dOgAtVqNRYsWYfTo0TrnmZ55LrC0LF1dXXHt2jWIxWLGDvOPP/6Y8yUf7F9KDBBC8Oqrr1q0+ld1QkNDGafDLly4EMeOHbMq7OqoVCpMnToVsbGx2LFjBx4/fgy1Wo179+45dLMDALzzzjvaqdc1yc3NxWeffWZ0lIiA6SxevJjX9U/MxdXVFS1bttQzWG5uboiPj0dAQICdlFX+Kaenp+PevXtYs2YN1q9fr+cnKioKcXFxnMa7atUqs4cYN27cGGvWrEGrVq3QsmVLxtUnHz9+rDfKa8GCBVYNh3TIGriltGvXDl27dsWVK1cwaNAguLm5MfpLSEjA33//zUmcpaWl2L9/PzZs2ODwxpqJrl27YtiwYYznioqK8O9//9vGipyXxo0bY8CAAToLFQGVy5Fqmic+/vhjXtZA0RAcHKztXLVmVJSLiwsmT56MFStWmDU4wFq6d++uN1wUgHYYaM0m1Y4dO0KlUmHJkiWcafjjjz8QFhaGkSNHmuS/efPmGDp0KCZNmqR3Ti6X46+//gJQWSGqyahRo5CXl6e3HrmpOJwB17x+WPJq9MknnyAkJATTp0/Hvn37bLLwTXZ2tl06erigbt26rONUy8vLkZ+fb2NFzoNCoUBubi4CAgK091nv3r3RvHlzhIeH6/jt0qWLzSZSRUZGYufOnTaJi2sCAgKwbNky7Z+dszB8+HDG/iG5XI709HS8/fbbrNfm5+ejrKzM4rgdzoCHhYUZrB1TSg0a5v79++P27dus552lY9EWJCUl6RkboDKPtm3bxlijEKjk0qVLCA0NRXFxsc792KRJEzx79syOyrjD1s/K3bt37brxBdf89ddfBo03APTs2dOqOByyDdwQNdfSNQeFQoHg4GDcunWLY1W1i48++ghffvmlvWUI2JHy8nI0bNgQDx48sJsGd3d3PHnyBKGhoQb9tW/fHllZWQ7R8WprHK4Gboz8/HzMmzcPGRkZJg8xrE5eXp7JY8VrKyKRCHv27GGdvVhSUmL5Fk8CTsOpU6ewYsUKEEKwa9cunTXYKaXIy8uz68geQggCAgKwceNGSKVSNGzYkNGfq6sr6tevb7O1wjVs374dPj4+aNasmd65+Ph4bNq0iXcNDmXA27Vrxzj9tCbJycno2rWrDRTVTgghGDx4MOOkl19++cWms+6cGYVCgfj4eBBC0K9fP7Rq1crekkzm2LFj2LZtG37//XcAwLp163Tuh4qKCps1oXh5eWHChAmso8769OljEx3mMnDgQPj7++sd37FjB3bs2KFd5oFPHMqA9+nTB/Pnz2c8p1QqkZ6ebnHtWS6X4969ey99G7irqytatGjBWluJi4tDTk6OjVU5JxUVFZg2bRqAytmVjmDAi4uLtZNzWrRowTq+/8iRI/jzzz+1v2fOnGkTfUzUqVMHa9eutSoMQghatWqFe/fucTLs9cWLF3jw4IFe7VoikaB58+aMlRxKKe7evYv58+cjIyPDag2m4DCNRoYGz6vVauTl5SEsLAwFBQUAKjPLHGN+7949tGvXzimH+nFJSEgIbt68afUYe0fD2GQkoLISwNcfuEqlglKpZHRs96m597Ap/PnnnwgLC0NYWJjB0Q1LlixxiJm1TOWmVqtZ81Ljapaju7s7bt68ydicYS4ikQibN29mXH2xX79+OHv2LOMkooqKCrRt29ZmxhtwIAP+22+/se4Jd+jQIYSEhOgcW7dunUNNiBCwL2PHjtVZTY+JsLAw7Nmzh5f4J02apLPscXXXv39/xmuysrLg4+PzUvc3jBgxAnfv3tU59uOPP7LmpUQigY+PD4qKinjTdODAAYPjyhs0aIDS0lLUrVuXNw2mYpIBJ4TUIYQkEELuEEJuE0K6EULqEUIOE0LuVX1alRpDC8io1Wq9ZU5VKhVu3bqFN954w+gr0+7du/Wm4QrULsRisdG3Crlczkmn3KRJk5CcnKx1DRs2hEKhgFwu13PR0dGIj4/XC+PPP//E0KFDDS7f+zIgFov1+mKUSiVjXmqcTCZDnz59cOnSJV40ubm5ISYmBtu3b2c8TwiBh4eHTg08LS0N3bt3t/kbvqk18NUA/qKUtgbQAcBtVO6DeZRS2gKVW6rNsVTEvHnz0LJlS7Ovk8lkSE1NNfpanJubKwwdROWEkhkzZjCeKy8vR1xcHIqLi22sqpIHDx7g22+/NViWn332Geu049TUVIt29rGERo0aITw8XOvmz5+Pjh076vmbPHkyxo8fj9atW+ude/HiBWezgWsTGzduxKFDh4z6u3r1KuO9OmPGDHTp0sUqDZs2bUJqairjjFAmzpw5gxUrVugtz2sLjHZiEkJ8AfQEEAMAlNIKABWEkBGo3CMTAH4BcALA/7NERNeuXVlfR9LT01lfjb28vNC1a1fWDrnz589DoVAgPT3dElkm4enpyTgZRgPbdP7OnTvD19dX7/itW7d4mwHZsWNHfPrpp3rHCwoKcP78eSxdupSXeE3h0aNHWLlypcG1kidMmIC7d+8yTjvOzc1l7fVXKpU4d+4cb7XdqVOnoqCgQG/DiWnTpqFdu3a8xMkFAQEB6Nq1Ky5evGiX+Fu0aIGwsDAAlf0B586dw9q1a3HlyhWLw4yNjUVqaqpVm0/s3LkTwcHBGDx4sEn+L126ZJMhg4wwbZRZ3QHoCOASgM0ArgDYCMAbQGENfwUs108GcLnKsW7amZCQQIuLi/VcbGws6zVhYWFaf0qlUm/D0Pr16/O66aqrqyvt3LmzwU1LzWXMmDHU3d2dc60eHh502rRpjHEeOXKE13wy1fn4+BjdWDcuLo4xbbGxsYz+FQoFffz4MWcaPT096eLFi60q47KyMrpx40be87O4uNioluzsbCqRSGxe1t7e3nTz5s1aHZbsNH/48GHGNH3++efUw8PDKn3Tp0+npaWlRvNPKpXSJUuW2CLPLNuVHkA4ACWArlW/VwNYBBMNeA0/BkXW3DHelB27Nf6uX7+ul7l8G/DPPvuM093eKa28kePj4znXumfPHlatzm7At2/fznrdqVOnON35/cyZM1aX+bhx42ySn6YYcM3O9D4+PjYt67S0NJ185NKAq9VqmpCQYLXGjh07Gs2/qKgoW+WZxbvSZwPIppRq3rMSALwO4BkhJAgAqj71l9oyEyaBpl4zaNAg/PzzzwAq2xdDQkLw4sULayUZhevZX4QQjB07FkeOHOE0XE3Yzs6sWbOwc+dOeHt7IyMjAw8ePMDw4cP10vbOO+8gJCQEo0aN4nTo4MiRIy3ayamsrAyhoaEICQlBYmIiZ3qshRBi0/vC3d0d6enpaNasmV68165d0+5aZA2EEAwaNMjqpiFT7Y89MdoGTil9SgjJIoS0opSmAegH4FaVmwBgWdWnbZZbYyEnJwfx8fE4fvw45HI5MjMz7SnHKnx8fBAcHGyTuHbt2oX//Oc/NonLEK1btzZpr8C6desiKCgIhBCEhISwGp8nT57wcg88ffoUhYWFJvtPTExEYmIilEqlXdcVMcb69euxcOFC7SQgvtCUW82x34QQNG3alLNtCL29vdGkSRNOwmKCUoopU6Zw0hE9fvx4+Pv7Y9WqVWZfa+pMzOkAthFC3ABkAJiIyhEsuwkhHwN4BOB9s2PnGM2wLmcnPT0df/zxB6dhnj17Fk2bNtXroU9NTbV4cTAuCQwMxJgxY6wKo7S0FAcPHgQAXpfCvXHjBnbu3AkXFxe89957Bmuw165dw9atW3nTwgWEEIwZMwbr16/n3YA7O9nZ2bh8+TJGjBiB3bt3c/KWHxERgVdeeYU/A04pvYrKtvCa9DM7xlqEVCpFdnY25+EmJCRg7ty5nIa5atUq5ObmYuXKlQgMDMTjx48BVC5c5Yjk5+ejvLyc8Vxubi4opcjOztYxno8ePbL6T8AU9u7di7179xodBQXAbsMygcodYJh2pGLDFmPSNeXGNmtWJpOZHFZeXp7B549pAwVzUCgUyM7ORnBwMJ49ewalUolDhw5h3rx5GDFihFVhV6ewsJB1XX6jMLU78+Vgw04SwTG7Fi1aUIVCwctIF2tcr169qFqt1rrRo0fbXZPgBOfm5kYrKipoq1attMcCAwOpWq2m9erVs6UWxk5MYstG+KrRAAJ2RCQS8T4V2RLEYrFObbGsrEzYi1PAIfDz80NJSYl2Fi8hBL6+viguLrZlJ2YKpVSvFUQw4AICAgKOD6MBd5jFrAQEBAQEzEMw4AICAgJOimDABQQEBJwUW+/IkwdAWvX5MlEfQppfBoQ0vxzYI81NmQ7atBMTAAghl5ka42szQppfDoQ0vxw4UpqFJhQBAQEBJ0Uw4AICAgJOij0M+AY7xGlvhDS/HAhpfjlwmDTbvA1cQEBAQIAbhCYUAQEBASfFZgacEDKIEJJGCEknhFi8AbKjQwh5SAj5mxBylRByuepYPULIYULIvapP5g1AnQRCyCZCSC4h5Ea1Y6xpJITMrSr3NEJIlH1UWwdLmr8hhDyuKuurhJDB1c7VhjQ3IYQcJ4TcJoTcJIR8UXW81pa1gTQ7ZlnbaBVCMYD7AEIBuAG4BqCNLVdCtOGKiw8B1K9xbAWAOVXf5wBYbm+dVqaxJyp3ZbphLI0A2lSVtzuAZlX3gdjeaeAozd8AmMXgt7akOQjA61XffQDcrUpbrS1rA2l2yLK2VQ08AkA6pTSDVu5qvxPACBvF7QiMAPBL1fdfALxtPynWQyk9BaDmSvZsaRwBYCelVE4pfQAgHZX3g1PBkmY2akuan1BKU6u+lwC4DSAYtbisDaSZDbum2VYGPBhAVrXf2TCcKc4MBZBECEkhhEyuOhZIKX0CVN4gABrYTR1/sKWxtpf9NELI9aomFk1TQq1LMyEkBEAnABfxkpR1jTQDDljWtjLgTFuW1NbhL29SSl8H8BaAqYSQnvYWZGdqc9nHA2gOoCOAJwBWVh2vVWkmhEgA7AXwD0qpoS2Gak26GdLskGVtKwOeDaD6DqONAeTYKG6bQinNqfrMBZCIytepZ4SQIACo+rRuryfHhC2NtbbsKaXPKKUqSqkawL/xf6/OtSbNhBBXVBqybZTS36oO1+qyZkqzo5a1rQx4MoAWhJBmVRsjfwDggI3ithmEEG9CiI/mO4CBAG6gMq0TqrxNALDfPgp5hS2NBwB8QAhxJ4Q0A9ACwCU76OMcjRGr4h1UljVQS9JMKjf7/A+A25TSH6qdqrVlzZZmhy1rG/buDkZlj+59APPs3dvMUxpDUdkjfQ3ATU06AfgDOArgXtVnPXtrtTKdO1D5GqlAZQ3kY0NpBDCvqtzTALxlb/0cpnkrgL8BXEflgxxUy9IcicrmgOsArla5wbW5rA2k2SHLWpiJKSAgIOCkCDMxBQQEBJwUwYALCAgIOCmCARcQEBBwUgQDLiAgIOCkCAZcQEBAwEkRDLiAgICAkyIYcAEBAQEnRTDgAgICAk7K/wdQpoPSBq9kbAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 显示图像\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# 打印标签\n",
    "print(\" \".join('%5s' % classes[labels[j]] for j in range(8))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 模型训练1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNNNet(\n",
      "  (conv1): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(16, 36, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=1296, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=36, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 如果有gpu的可使用GPU加速\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class CNNNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNNet, self).__init__()\n",
    "        # 定义第一个卷积层\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1)\n",
    "        # 定义第一个池化层\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        # 定义第二个卷积层\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=36, kernel_size=3, stride=1)\n",
    "        # 定义第二个池化层\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        # 定义第一个全连接层\n",
    "        self.fc1 = nn.Linear(1296, 128)\n",
    "        # 定义第二个全连接层\n",
    "        self.fc2 = nn.Linear(128, 36)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # 连接各个cnn各个模块\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        # print(x.shape)\n",
    "        x=x.view(-1, 36*6*6)\n",
    "        x=F.relu(self.fc2(F.relu(self.fc1(x))))\n",
    "        # 返回运算后的结果\n",
    "        return x\n",
    "\n",
    "# 实例化模型\n",
    "net = CNNNet()\n",
    "net.to(device)  # 模型设备转移\n",
    "# 查看模型\n",
    "print(net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 选择优化器\n",
    "import torch.optim as optim\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=lr, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 150] loss:3.562\n",
      "[1, 300] loss:3.473\n",
      "[1, 450] loss:3.068\n",
      "[2, 150] loss:1.933\n",
      "[2, 300] loss:1.740\n",
      "[2, 450] loss:1.729\n",
      "[3, 150] loss:1.567\n",
      "[3, 300] loss:1.420\n",
      "[3, 450] loss:1.360\n",
      "[4, 150] loss:1.324\n",
      "[4, 300] loss:1.311\n",
      "[4, 450] loss:1.292\n",
      "[5, 150] loss:1.230\n",
      "[5, 300] loss:1.183\n",
      "[5, 450] loss:1.129\n",
      "[6, 150] loss:1.019\n",
      "[6, 300] loss:0.889\n",
      "[6, 450] loss:0.786\n",
      "[7, 150] loss:0.753\n",
      "[7, 300] loss:0.762\n",
      "[7, 450] loss:0.760\n",
      "[8, 150] loss:0.706\n",
      "[8, 300] loss:0.742\n",
      "[8, 450] loss:0.643\n",
      "[9, 150] loss:0.602\n",
      "[9, 300] loss:0.614\n",
      "[9, 450] loss:0.591\n",
      "[10, 150] loss:0.596\n",
      "[10, 300] loss:0.594\n",
      "[10, 450] loss:0.530\n",
      "[11, 150] loss:0.481\n",
      "[11, 300] loss:0.475\n",
      "[11, 450] loss:0.470\n",
      "[12, 150] loss:0.462\n",
      "[12, 300] loss:0.440\n",
      "[12, 450] loss:0.342\n",
      "[13, 150] loss:0.356\n",
      "[13, 300] loss:0.345\n",
      "[13, 450] loss:0.328\n",
      "[14, 150] loss:0.337\n",
      "[14, 300] loss:0.329\n",
      "[14, 450] loss:0.340\n",
      "[15, 150] loss:0.322\n",
      "[15, 300] loss:0.315\n",
      "[15, 450] loss:0.320\n",
      "[16, 150] loss:0.315\n",
      "[16, 300] loss:0.301\n",
      "[16, 450] loss:0.302\n",
      "[17, 150] loss:0.302\n",
      "[17, 300] loss:0.309\n",
      "[17, 450] loss:0.295\n",
      "[18, 150] loss:0.280\n",
      "[18, 300] loss:0.290\n",
      "[18, 450] loss:0.281\n",
      "[19, 150] loss:0.262\n",
      "[19, 300] loss:0.282\n",
      "[19, 450] loss:0.277\n",
      "[20, 150] loss:0.261\n",
      "[20, 300] loss:0.280\n",
      "[20, 450] loss:0.265\n",
      "[21, 150] loss:0.250\n",
      "[21, 300] loss:0.259\n",
      "[21, 450] loss:0.273\n",
      "[22, 150] loss:0.248\n",
      "[22, 300] loss:0.254\n",
      "[22, 450] loss:0.255\n",
      "[23, 150] loss:0.252\n",
      "[23, 300] loss:0.238\n",
      "[23, 450] loss:0.250\n",
      "[24, 150] loss:0.239\n",
      "[24, 300] loss:0.249\n",
      "[24, 450] loss:0.244\n",
      "[25, 150] loss:0.237\n",
      "[25, 300] loss:0.232\n",
      "[25, 450] loss:0.244\n",
      "[26, 150] loss:0.243\n",
      "[26, 300] loss:0.217\n",
      "[26, 450] loss:0.232\n",
      "[27, 150] loss:0.227\n",
      "[27, 300] loss:0.167\n",
      "[27, 450] loss:0.133\n",
      "[28, 150] loss:0.126\n",
      "[28, 300] loss:0.132\n",
      "[28, 450] loss:0.125\n",
      "[29, 150] loss:0.120\n",
      "[29, 300] loss:0.126\n",
      "[29, 450] loss:0.121\n",
      "[30, 150] loss:0.120\n",
      "[30, 300] loss:0.117\n",
      "[30, 450] loss:0.126\n",
      "[31, 150] loss:0.112\n",
      "[31, 300] loss:0.115\n",
      "[31, 450] loss:0.109\n",
      "[32, 150] loss:0.099\n",
      "[32, 300] loss:0.118\n",
      "[32, 450] loss:0.107\n",
      "[33, 150] loss:0.100\n",
      "[33, 300] loss:0.098\n",
      "[33, 450] loss:0.106\n",
      "[34, 150] loss:0.104\n",
      "[34, 300] loss:0.108\n",
      "[34, 450] loss:0.100\n",
      "[35, 150] loss:0.101\n",
      "[35, 300] loss:0.098\n",
      "[35, 450] loss:0.105\n",
      "[36, 150] loss:0.095\n",
      "[36, 300] loss:0.100\n",
      "[36, 450] loss:0.101\n",
      "[37, 150] loss:0.093\n",
      "[37, 300] loss:0.094\n",
      "[37, 450] loss:0.099\n",
      "[38, 150] loss:0.099\n",
      "[38, 300] loss:0.084\n",
      "[38, 450] loss:0.094\n",
      "[39, 150] loss:0.088\n",
      "[39, 300] loss:0.083\n",
      "[39, 450] loss:0.094\n",
      "[40, 150] loss:0.083\n",
      "[40, 300] loss:0.087\n",
      "[40, 450] loss:0.093\n",
      "[41, 150] loss:0.080\n",
      "[41, 300] loss:0.082\n",
      "[41, 450] loss:0.082\n",
      "[42, 150] loss:0.078\n",
      "[42, 300] loss:0.082\n",
      "[42, 450] loss:0.086\n",
      "[43, 150] loss:0.082\n",
      "[43, 300] loss:0.085\n",
      "[43, 450] loss:0.084\n",
      "[44, 150] loss:0.074\n",
      "[44, 300] loss:0.071\n",
      "[44, 450] loss:0.082\n",
      "[45, 150] loss:0.079\n",
      "[45, 300] loss:0.074\n",
      "[45, 450] loss:0.075\n",
      "[46, 150] loss:0.075\n",
      "[46, 300] loss:0.078\n",
      "[46, 450] loss:0.076\n",
      "[47, 150] loss:0.069\n",
      "[47, 300] loss:0.071\n",
      "[47, 450] loss:0.073\n",
      "[48, 150] loss:0.072\n",
      "[48, 300] loss:0.073\n",
      "[48, 450] loss:0.071\n",
      "[49, 150] loss:0.070\n",
      "[49, 300] loss:0.068\n",
      "[49, 450] loss:0.078\n",
      "[50, 150] loss:0.069\n",
      "[50, 300] loss:0.067\n",
      "[50, 450] loss:0.064\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "mini_batch = 150\n",
    "n_epochs = 50\n",
    "## 训练模型\n",
    "for epoch in range(n_epochs):\n",
    "    running_loss = 0.0\n",
    "    # 迭代，批次训练\n",
    "    for i, data in enumerate(trainloader):\n",
    "        # 获取训练数据\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        # 权重参数梯度清零\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 正向传播\n",
    "        outputs = net(inputs)\n",
    "        # 计算损失值\n",
    "        loss = criterion(outputs, labels)\n",
    "        # 反向传播\n",
    "        loss.backward()\n",
    "        # 参数更新\n",
    "        optimizer.step()\n",
    "        # 损失值累加\n",
    "        running_loss += loss.item()\n",
    "        # 每2000个mini-batch显示一次损失值\n",
    "        if i % mini_batch == (mini_batch-1):\n",
    "            print('[%d, %d] loss:%.3f' % (epoch + 1, i + 1, running_loss / mini_batch))\n",
    "            running_loss = 0.0\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#验证准确率\n",
    "def accuracy_test(model,dataloader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.cuda() # 将模型放入GPU计算，能极大加快运算速度\n",
    "    with torch.no_grad(): # 使用验证集时关闭梯度计算\n",
    "        for data in dataloader:\n",
    "           \n",
    "            images,labels = data\n",
    "            images,labels = images.to('cuda'),labels.to('cuda')\n",
    "\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data,1) \n",
    "            # torch.max返回输出结果中，按dim=1行排列的每一行最大数据及他的索引，丢弃数据，保留索引\n",
    "            total += labels.size(0)\n",
    "            \n",
    "            correct += (predicted == labels).sum().item()\n",
    "            #将预测及标签两相同大小张量逐一比较各相同元素的个数\n",
    "    print('the accuracy is {:.4f}'.format(correct/total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc on test: 34 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images,labels = data\n",
    "        images,labels = images.to('cuda'),labels.to('cuda')\n",
    "        outputs = net(images)\n",
    "        _,predicted = torch.max(outputs.data,dim=1)\n",
    "        total += labels.size(0)\n",
    "        correct+=(predicted==labels).sum().item()\n",
    "    print(\"acc on test: %d %%\" % (100*correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy is 0.3424\n"
     ]
    }
   ],
   "source": [
    "accuracy_test(net,testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型训练2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设备配置\n",
    "torch.cuda.set_device(0) # 这句用来设置pytorch在哪块GPU上运行\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 超参数设置\n",
    "num_epochs = 50\n",
    "num_classes = 36\n",
    "image_size = 32  #图像的总尺寸32*32\n",
    "learning_rate = 0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "                                       transforms.Grayscale(),\n",
    "                                       transforms.RandomRotation(5),\n",
    "                                       transforms.Resize(32),\n",
    "                                       transforms.ToTensor(), # 归一化  对图像进行张量化，以便神经网络处理\n",
    "                                       transforms.Normalize([0.5],[0.5]) #变换到【-1 ，1】\n",
    "                                      ])\n",
    "\n",
    "\n",
    "test_valid_transforms = transforms.Compose([\n",
    "                                       transforms.Grayscale(),\n",
    "                                       transforms.Resize(32),\n",
    "                                       transforms.ToTensor(), #归一化  对图像进行张量化，以便神经网络处理\n",
    "                                       transforms.Normalize([0.5],[0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"../result/augment_data/train/\"\n",
    "test_dir = \"../result/augment_data/test/\"\n",
    "test_data = datasets.ImageFolder(test_dir,transform = test_valid_transforms)\n",
    "train_data = datasets.ImageFolder(train_dir,transform = train_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "testAll_loader = torch.utils.data.DataLoader(test_data,batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#下标\n",
    "batch_size = 8  # 一个batch 的大小\n",
    "indices = range(len(test_data))\n",
    "indices_val = indices[:1482]\n",
    "indices_test = indices[1482:]  \n",
    "# 通过下标对验证集和测试集进行采样\n",
    "sampler_val = torch.utils.data.sampler.SubsetRandomSampler(indices_val)\n",
    "sampler_test = torch.utils.data.sampler.SubsetRandomSampler(indices_test)\n",
    "# 根据采样器来定义加载器，然后加载数据\n",
    "validation_loader = torch.utils.data.DataLoader(dataset =test_data,batch_size = batch_size,sampler = sampler_val)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_data,batch_size=batch_size,sampler = sampler_test)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data,batch_size=batch_size,shuffle=True,num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4474\n",
      "35792\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loader))\n",
    "print(len(train_loader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义两个卷积层的厚度（feature map的数量）\n",
    "depth = [4, 8]\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1,depth[0],5,padding=2) # 1 input channel, 4 output channels, 5x5 square convolution kernel\n",
    "        self.pool = nn.MaxPool2d(2, 2) #定义一个Pooling层\n",
    "        self.conv2 = nn.Conv2d(depth[0],depth[1],5, padding = 2) #第二层卷积:4input channel, 8 output channels, 5x5 square convolution kernel\n",
    "        self.fc1 = nn.Linear( depth[1] * image_size // 4 * image_size // 4 , 512) #线性连接层的输入尺寸为最后一层立方体的平铺，输出层512个节点\n",
    "        self.fc2 = nn.Linear(512, num_classes) #最后一层线性分类单元，输入为512，输出为要做分类的类别数  \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x尺寸：(batch_size, image_channels, image_width, image_height)\n",
    "        x = F.relu(self.conv1(x))  #第一层卷积的激活函数用ReLu\n",
    "        x = self.pool(x) #第二层pooling，将片变小\n",
    "        \n",
    "        #x的尺寸：(batch_size, depth[0], image_width/2, image_height/2)\n",
    "        x = F.relu(self.conv2(x)) #第三层卷积，输入输出通道分别为depth[0]=4, depth[1]=8\n",
    "        x = self.pool(x) #第四层pooling，将图片缩小到原大小的1/4\n",
    "        \n",
    "        #x的尺寸：(batch_size, depth[1], image_width/4, image_height/4)\n",
    "        # view函数将张量x变形成一维的向量形式，总特征数batch_size * (image_size//4)^2*depth[1]不改变，为接下来的全连接作准备。\n",
    "        x = x.view(-1, image_size // 4 * image_size // 4 * depth[1])\n",
    "        \n",
    "        #x的尺寸：(batch_size, depth[1]*image_width/4*image_height/4)\n",
    "        x = F.relu(self.fc1(x)) #第五层为全链接，ReLu激活函数\n",
    "        \n",
    "        #x的尺寸：(batch_size, 512)\n",
    "        # dropout 参数training：pply dropout if is True. Defualt: True\n",
    "        x = F.dropout(x, training=self.training) #以默认为0.5的概率对这一层进行dropout操作，为了防止过拟合\n",
    "        x = self.fc2(x) \n",
    "        \n",
    "        #x的尺寸：(batch_size, num_classes)\n",
    "        #输出层为log_softmax，即概率对数值log(p(x))。采用log_softmax可以使得后面的交叉熵计算更快\n",
    "        #log_softmax虽然等价于log(softmax(x))，但是分开两个运算会速度比较慢，数值也不稳定。\n",
    "        # dim=0 ，即softmax后横向的和为1\n",
    "        x = F.log_softmax(x, dim = 0) \n",
    "        return x\n",
    "    \n",
    "    def retrieve_features(self, x):\n",
    "        #该函数专门用于提取卷积神经网络的特征图的功能，返回feature_map1, feature_map2为前两层卷积层的特征图\n",
    "        feature_map1 = F.relu(self.conv1(x)) #完成第一层卷积\n",
    "        x = self.pool(feature_map1)  # 完成第一层pooling\n",
    "        #print('type(feature_map1)=',feature_map1)\n",
    "        #type是一个四维的tensor\n",
    "        feature_map2 = F.relu(self.conv2(x)) #第二层卷积，两层特征图都存储到了feature_map1, feature_map2中\n",
    "        return (feature_map1, feature_map2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"计算预测正确率的函数，其中predictions是模型给出的一组预测结果：batch_size行num_classes列的矩阵，labels是真正的label\"\"\"\n",
    "def accuracy(predictions, labels):\n",
    "    # torch.max的输出：out (tuple, optional维度) – the result tuple of two output tensors (max, max_indices)\n",
    "    pred = torch.max(predictions.data, 1)[1] # 对于任意一行（一个样本）的输出值的第1个维度，求最大，得到每一行的最大元素的下标\n",
    "    right_num = pred.eq(labels.data.view_as(pred)).sum() #将下标与labels中包含的类别进行比较，并累计得到比较正确的数量\n",
    "    return right_num, len(labels) #返回正确的数量和这一次一共比较了多少元素\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] [3992/35792]  Loss: 2.666  训练集准确率: 19.50%  验证集准确率: 12.28%\n",
      "Epoch [1/50] [7992/35792]  Loss: 1.854  训练集准确率: 34.01%  验证集准确率: 13.50%\n",
      "Epoch [1/50] [11992/35792]  Loss: 2.086  训练集准确率: 41.28%  验证集准确率: 18.89%\n",
      "Epoch [1/50] [15992/35792]  Loss: 1.241  训练集准确率: 46.10%  验证集准确率: 28.61%\n",
      "Epoch [1/50] [19992/35792]  Loss: 1.710  训练集准确率: 50.35%  验证集准确率: 25.17%\n",
      "Epoch [1/50] [23992/35792]  Loss: 0.914  训练集准确率: 53.45%  验证集准确率: 15.99%\n",
      "Epoch [1/50] [27992/35792]  Loss: 0.851  训练集准确率: 56.05%  验证集准确率: 21.79%\n",
      "Epoch [1/50] [31992/35792]  Loss: 0.940  训练集准确率: 58.16%  验证集准确率: 26.25%\n",
      "Epoch [2/50] [3992/35792]  Loss: 0.937  训练集准确率: 76.05%  验证集准确率: 29.15%\n",
      "Epoch [2/50] [7992/35792]  Loss: 2.056  训练集准确率: 76.03%  验证集准确率: 26.86%\n",
      "Epoch [2/50] [11992/35792]  Loss: 0.905  训练集准确率: 76.53%  验证集准确率: 30.03%\n",
      "Epoch [2/50] [15992/35792]  Loss: 0.920  训练集准确率: 76.97%  验证集准确率: 31.44%\n",
      "Epoch [2/50] [19992/35792]  Loss: 1.128  训练集准确率: 77.31%  验证集准确率: 34.75%\n",
      "Epoch [2/50] [23992/35792]  Loss: 1.146  训练集准确率: 77.68%  验证集准确率: 31.44%\n",
      "Epoch [2/50] [27992/35792]  Loss: 0.580  训练集准确率: 77.96%  验证集准确率: 34.28%\n",
      "Epoch [2/50] [31992/35792]  Loss: 0.615  训练集准确率: 78.27%  验证集准确率: 30.03%\n",
      "Epoch [3/50] [3992/35792]  Loss: 0.715  训练集准确率: 79.97%  验证集准确率: 30.50%\n",
      "Epoch [3/50] [7992/35792]  Loss: 1.017  训练集准确率: 80.28%  验证集准确率: 24.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x0000020A9D028DC0>\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1324, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1291, in _shutdown_workers\n",
      "    if self._persistent_workers or self._workers_status[worker_id]:\n",
      "AttributeError: '_MultiProcessingDataLoaderIter' object has no attribute '_workers_status'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/50] [11992/35792]  Loss: 1.055  训练集准确率: 80.59%  验证集准确率: 31.11%\n",
      "Epoch [3/50] [15992/35792]  Loss: 1.100  训练集准确率: 80.75%  验证集准确率: 33.00%\n",
      "Epoch [3/50] [19992/35792]  Loss: 0.850  训练集准确率: 80.86%  验证集准确率: 34.14%\n",
      "Epoch [3/50] [23992/35792]  Loss: 0.652  训练集准确率: 81.04%  验证集准确率: 30.23%\n",
      "Epoch [3/50] [27992/35792]  Loss: 1.068  训练集准确率: 81.17%  验证集准确率: 28.41%\n",
      "Epoch [3/50] [31992/35792]  Loss: 1.233  训练集准确率: 81.30%  验证集准确率: 33.20%\n",
      "Epoch [4/50] [3992/35792]  Loss: 0.950  训练集准确率: 83.22%  验证集准确率: 35.96%\n",
      "Epoch [4/50] [7992/35792]  Loss: 0.504  训练集准确率: 82.95%  验证集准确率: 37.04%\n",
      "Epoch [4/50] [11992/35792]  Loss: 0.602  训练集准确率: 83.07%  验证集准确率: 31.71%\n",
      "Epoch [4/50] [15992/35792]  Loss: 0.539  训练集准确率: 82.94%  验证集准确率: 30.77%\n",
      "Epoch [4/50] [19992/35792]  Loss: 1.060  训练集准确率: 82.89%  验证集准确率: 35.49%\n",
      "Epoch [4/50] [23992/35792]  Loss: 1.287  训练集准确率: 82.82%  验证集准确率: 35.90%\n",
      "Epoch [4/50] [27992/35792]  Loss: 0.500  训练集准确率: 82.92%  验证集准确率: 35.56%\n",
      "Epoch [4/50] [31992/35792]  Loss: 0.512  训练集准确率: 82.89%  验证集准确率: 30.30%\n",
      "Epoch [5/50] [3992/35792]  Loss: 0.892  训练集准确率: 83.75%  验证集准确率: 31.92%\n",
      "Epoch [5/50] [7992/35792]  Loss: 0.756  训练集准确率: 84.00%  验证集准确率: 41.30%\n",
      "Epoch [5/50] [11992/35792]  Loss: 0.534  训练集准确率: 83.58%  验证集准确率: 40.82%\n",
      "Epoch [5/50] [15992/35792]  Loss: 0.762  训练集准确率: 83.47%  验证集准确率: 25.91%\n",
      "Epoch [5/50] [19992/35792]  Loss: 0.449  训练集准确率: 83.64%  验证集准确率: 33.87%\n",
      "Epoch [5/50] [23992/35792]  Loss: 0.723  训练集准确率: 83.70%  验证集准确率: 32.52%\n",
      "Epoch [5/50] [27992/35792]  Loss: 0.965  训练集准确率: 83.62%  验证集准确率: 33.00%\n",
      "Epoch [5/50] [31992/35792]  Loss: 1.217  训练集准确率: 83.61%  验证集准确率: 35.63%\n",
      "Epoch [6/50] [3992/35792]  Loss: 0.482  训练集准确率: 83.78%  验证集准确率: 34.35%\n",
      "Epoch [6/50] [7992/35792]  Loss: 1.069  训练集准确率: 84.09%  验证集准确率: 39.14%\n",
      "Epoch [6/50] [11992/35792]  Loss: 1.015  训练集准确率: 84.26%  验证集准确率: 32.79%\n",
      "Epoch [6/50] [15992/35792]  Loss: 0.704  训练集准确率: 84.41%  验证集准确率: 28.34%\n",
      "Epoch [6/50] [19992/35792]  Loss: 0.726  训练集准确率: 84.30%  验证集准确率: 34.28%\n",
      "Epoch [6/50] [23992/35792]  Loss: 1.124  训练集准确率: 84.39%  验证集准确率: 39.61%\n",
      "Epoch [6/50] [27992/35792]  Loss: 1.171  训练集准确率: 84.56%  验证集准确率: 36.03%\n",
      "Epoch [6/50] [31992/35792]  Loss: 1.797  训练集准确率: 84.51%  验证集准确率: 43.72%\n",
      "Epoch [7/50] [3992/35792]  Loss: 0.455  训练集准确率: 84.65%  验证集准确率: 34.41%\n",
      "Epoch [7/50] [7992/35792]  Loss: 0.453  训练集准确率: 84.71%  验证集准确率: 39.00%\n",
      "Epoch [7/50] [11992/35792]  Loss: 0.871  训练集准确率: 84.70%  验证集准确率: 41.77%\n",
      "Epoch [7/50] [15992/35792]  Loss: 0.518  训练集准确率: 84.71%  验证集准确率: 36.37%\n",
      "Epoch [7/50] [19992/35792]  Loss: 0.605  训练集准确率: 84.81%  验证集准确率: 39.68%\n",
      "Epoch [7/50] [23992/35792]  Loss: 0.529  训练集准确率: 85.05%  验证集准确率: 38.87%\n",
      "Epoch [7/50] [27992/35792]  Loss: 0.883  训练集准确率: 85.24%  验证集准确率: 33.74%\n",
      "Epoch [7/50] [31992/35792]  Loss: 0.703  训练集准确率: 85.27%  验证集准确率: 37.99%\n",
      "Epoch [8/50] [3992/35792]  Loss: 0.488  训练集准确率: 85.97%  验证集准确率: 35.96%\n",
      "Epoch [8/50] [7992/35792]  Loss: 0.547  训练集准确率: 85.61%  验证集准确率: 39.81%\n",
      "Epoch [8/50] [11992/35792]  Loss: 0.769  训练集准确率: 85.65%  验证集准确率: 37.04%\n",
      "Epoch [8/50] [15992/35792]  Loss: 0.844  训练集准确率: 85.70%  验证集准确率: 37.45%\n",
      "Epoch [8/50] [19992/35792]  Loss: 0.479  训练集准确率: 85.52%  验证集准确率: 44.06%\n",
      "Epoch [8/50] [23992/35792]  Loss: 0.450  训练集准确率: 85.69%  验证集准确率: 44.67%\n",
      "Epoch [8/50] [27992/35792]  Loss: 0.461  训练集准确率: 85.64%  验证集准确率: 41.09%\n",
      "Epoch [8/50] [31992/35792]  Loss: 1.086  训练集准确率: 85.52%  验证集准确率: 36.64%\n",
      "Epoch [9/50] [3992/35792]  Loss: 0.647  训练集准确率: 85.80%  验证集准确率: 43.25%\n",
      "Epoch [9/50] [7992/35792]  Loss: 0.580  训练集准确率: 85.85%  验证集准确率: 41.16%\n",
      "Epoch [9/50] [11992/35792]  Loss: 0.449  训练集准确率: 85.88%  验证集准确率: 42.44%\n",
      "Epoch [9/50] [15992/35792]  Loss: 0.457  训练集准确率: 85.99%  验证集准确率: 40.15%\n",
      "Epoch [9/50] [19992/35792]  Loss: 0.964  训练集准确率: 86.03%  验证集准确率: 37.31%\n",
      "Epoch [9/50] [23992/35792]  Loss: 0.586  训练集准确率: 85.78%  验证集准确率: 33.81%\n",
      "Epoch [9/50] [27992/35792]  Loss: 0.696  训练集准确率: 85.86%  验证集准确率: 37.79%\n",
      "Epoch [9/50] [31992/35792]  Loss: 0.650  训练集准确率: 85.89%  验证集准确率: 41.50%\n",
      "Epoch [10/50] [3992/35792]  Loss: 0.757  训练集准确率: 85.18%  验证集准确率: 41.57%\n",
      "Epoch [10/50] [7992/35792]  Loss: 0.465  训练集准确率: 85.78%  验证集准确率: 35.09%\n",
      "Epoch [10/50] [11992/35792]  Loss: 0.441  训练集准确率: 86.08%  验证集准确率: 39.54%\n",
      "Epoch [10/50] [15992/35792]  Loss: 0.549  训练集准确率: 86.36%  验证集准确率: 36.44%\n",
      "Epoch [10/50] [19992/35792]  Loss: 0.445  训练集准确率: 86.35%  验证集准确率: 34.89%\n",
      "Epoch [10/50] [23992/35792]  Loss: 0.854  训练集准确率: 86.28%  验证集准确率: 44.33%\n",
      "Epoch [10/50] [27992/35792]  Loss: 0.754  训练集准确率: 86.31%  验证集准确率: 41.63%\n",
      "Epoch [10/50] [31992/35792]  Loss: 0.823  训练集准确率: 86.33%  验证集准确率: 41.90%\n",
      "Epoch [11/50] [3992/35792]  Loss: 0.855  训练集准确率: 86.20%  验证集准确率: 41.63%\n",
      "Epoch [11/50] [7992/35792]  Loss: 0.515  训练集准确率: 86.19%  验证集准确率: 36.71%\n",
      "Epoch [11/50] [11992/35792]  Loss: 0.836  训练集准确率: 86.62%  验证集准确率: 40.82%\n",
      "Epoch [11/50] [15992/35792]  Loss: 1.004  训练集准确率: 86.64%  验证集准确率: 30.43%\n",
      "Epoch [11/50] [19992/35792]  Loss: 0.451  训练集准确率: 86.74%  验证集准确率: 37.92%\n",
      "Epoch [11/50] [23992/35792]  Loss: 0.469  训练集准确率: 86.58%  验证集准确率: 43.86%\n",
      "Epoch [11/50] [27992/35792]  Loss: 0.629  训练集准确率: 86.58%  验证集准确率: 40.42%\n",
      "Epoch [11/50] [31992/35792]  Loss: 0.438  训练集准确率: 86.55%  验证集准确率: 48.92%\n",
      "Epoch [12/50] [3992/35792]  Loss: 0.458  训练集准确率: 86.85%  验证集准确率: 32.86%\n",
      "Epoch [12/50] [7992/35792]  Loss: 0.526  训练集准确率: 86.65%  验证集准确率: 33.27%\n",
      "Epoch [12/50] [11992/35792]  Loss: 0.638  训练集准确率: 86.78%  验证集准确率: 39.34%\n",
      "Epoch [12/50] [15992/35792]  Loss: 0.717  训练集准确率: 86.78%  验证集准确率: 34.28%\n",
      "Epoch [12/50] [19992/35792]  Loss: 0.667  训练集准确率: 86.77%  验证集准确率: 38.19%\n",
      "Epoch [12/50] [23992/35792]  Loss: 0.988  训练集准确率: 86.75%  验证集准确率: 35.56%\n",
      "Epoch [12/50] [27992/35792]  Loss: 0.511  训练集准确率: 86.68%  验证集准确率: 37.04%\n",
      "Epoch [12/50] [31992/35792]  Loss: 0.449  训练集准确率: 86.65%  验证集准确率: 37.99%\n",
      "Epoch [13/50] [3992/35792]  Loss: 0.887  训练集准确率: 86.78%  验证集准确率: 33.20%\n",
      "Epoch [13/50] [7992/35792]  Loss: 0.448  训练集准确率: 87.55%  验证集准确率: 38.60%\n",
      "Epoch [13/50] [11992/35792]  Loss: 0.873  训练集准确率: 87.47%  验证集准确率: 32.32%\n",
      "Epoch [13/50] [15992/35792]  Loss: 0.739  训练集准确率: 87.41%  验证集准确率: 43.72%\n",
      "Epoch [13/50] [19992/35792]  Loss: 0.449  训练集准确率: 87.29%  验证集准确率: 42.85%\n",
      "Epoch [13/50] [23992/35792]  Loss: 0.448  训练集准确率: 87.26%  验证集准确率: 40.22%\n",
      "Epoch [13/50] [27992/35792]  Loss: 1.226  训练集准确率: 87.23%  验证集准确率: 40.42%\n",
      "Epoch [13/50] [31992/35792]  Loss: 0.447  训练集准确率: 87.18%  验证集准确率: 43.39%\n",
      "Epoch [14/50] [3992/35792]  Loss: 0.796  训练集准确率: 86.85%  验证集准确率: 42.65%\n",
      "Epoch [14/50] [7992/35792]  Loss: 0.690  训练集准确率: 87.32%  验证集准确率: 39.54%\n",
      "Epoch [14/50] [11992/35792]  Loss: 0.801  训练集准确率: 87.18%  验证集准确率: 41.16%\n",
      "Epoch [14/50] [15992/35792]  Loss: 0.569  训练集准确率: 87.20%  验证集准确率: 45.34%\n",
      "Epoch [14/50] [19992/35792]  Loss: 0.451  训练集准确率: 87.33%  验证集准确率: 39.00%\n",
      "Epoch [14/50] [23992/35792]  Loss: 0.444  训练集准确率: 87.32%  验证集准确率: 39.88%\n",
      "Epoch [14/50] [27992/35792]  Loss: 0.623  训练集准确率: 87.35%  验证集准确率: 48.31%\n",
      "Epoch [14/50] [31992/35792]  Loss: 0.446  训练集准确率: 87.33%  验证集准确率: 47.17%\n",
      "Epoch [15/50] [3992/35792]  Loss: 0.483  训练集准确率: 87.32%  验证集准确率: 37.52%\n",
      "Epoch [15/50] [7992/35792]  Loss: 0.821  训练集准确率: 87.50%  验证集准确率: 47.23%\n",
      "Epoch [15/50] [11992/35792]  Loss: 0.651  训练集准确率: 87.35%  验证集准确率: 48.79%\n",
      "Epoch [15/50] [15992/35792]  Loss: 0.449  训练集准确率: 87.36%  验证集准确率: 50.47%\n",
      "Epoch [15/50] [19992/35792]  Loss: 0.818  训练集准确率: 87.35%  验证集准确率: 37.65%\n",
      "Epoch [15/50] [23992/35792]  Loss: 0.773  训练集准确率: 87.28%  验证集准确率: 50.40%\n",
      "Epoch [15/50] [27992/35792]  Loss: 0.532  训练集准确率: 87.11%  验证集准确率: 50.13%\n",
      "Epoch [15/50] [31992/35792]  Loss: 0.535  训练集准确率: 87.08%  验证集准确率: 49.87%\n",
      "Epoch [16/50] [3992/35792]  Loss: 0.724  训练集准确率: 87.60%  验证集准确率: 51.75%\n",
      "Epoch [16/50] [7992/35792]  Loss: 2.255  训练集准确率: 87.51%  验证集准确率: 48.79%\n",
      "Epoch [16/50] [11992/35792]  Loss: 0.530  训练集准确率: 87.53%  验证集准确率: 46.22%\n",
      "Epoch [16/50] [15992/35792]  Loss: 0.713  训练集准确率: 87.36%  验证集准确率: 49.26%\n",
      "Epoch [16/50] [19992/35792]  Loss: 0.534  训练集准确率: 87.16%  验证集准确率: 49.19%\n",
      "Epoch [16/50] [23992/35792]  Loss: 0.721  训练集准确率: 87.25%  验证集准确率: 47.37%\n",
      "Epoch [16/50] [27992/35792]  Loss: 0.448  训练集准确率: 87.35%  验证集准确率: 47.03%\n",
      "Epoch [16/50] [31992/35792]  Loss: 0.439  训练集准确率: 87.44%  验证集准确率: 50.07%\n",
      "Epoch [17/50] [3992/35792]  Loss: 0.916  训练集准确率: 87.62%  验证集准确率: 46.02%\n",
      "Epoch [17/50] [7992/35792]  Loss: 0.451  训练集准确率: 87.57%  验证集准确率: 46.69%\n",
      "Epoch [17/50] [11992/35792]  Loss: 0.450  训练集准确率: 87.57%  验证集准确率: 40.28%\n",
      "Epoch [17/50] [15992/35792]  Loss: 0.992  训练集准确率: 87.50%  验证集准确率: 42.38%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/50] [19992/35792]  Loss: 1.414  训练集准确率: 87.46%  验证集准确率: 43.72%\n",
      "Epoch [17/50] [23992/35792]  Loss: 0.711  训练集准确率: 87.56%  验证集准确率: 42.51%\n",
      "Epoch [17/50] [27992/35792]  Loss: 0.448  训练集准确率: 87.47%  验证集准确率: 40.62%\n",
      "Epoch [17/50] [31992/35792]  Loss: 0.865  训练集准确率: 87.47%  验证集准确率: 45.28%\n",
      "Epoch [18/50] [3992/35792]  Loss: 0.447  训练集准确率: 87.80%  验证集准确率: 42.04%\n",
      "Epoch [18/50] [7992/35792]  Loss: 0.447  训练集准确率: 87.61%  验证集准确率: 43.05%\n",
      "Epoch [18/50] [11992/35792]  Loss: 0.508  训练集准确率: 87.68%  验证集准确率: 45.61%\n",
      "Epoch [18/50] [15992/35792]  Loss: 0.777  训练集准确率: 87.68%  验证集准确率: 46.29%\n",
      "Epoch [18/50] [19992/35792]  Loss: 0.693  训练集准确率: 87.54%  验证集准确率: 51.55%\n",
      "Epoch [18/50] [23992/35792]  Loss: 0.617  训练集准确率: 87.56%  验证集准确率: 46.49%\n",
      "Epoch [18/50] [27992/35792]  Loss: 1.131  训练集准确率: 87.59%  验证集准确率: 50.07%\n",
      "Epoch [18/50] [31992/35792]  Loss: 0.457  训练集准确率: 87.55%  验证集准确率: 50.61%\n",
      "Epoch [19/50] [3992/35792]  Loss: 0.446  训练集准确率: 88.53%  验证集准确率: 41.36%\n",
      "Epoch [19/50] [7992/35792]  Loss: 0.458  训练集准确率: 88.49%  验证集准确率: 44.74%\n",
      "Epoch [19/50] [11992/35792]  Loss: 0.818  训练集准确率: 88.03%  验证集准确率: 51.21%\n",
      "Epoch [19/50] [15992/35792]  Loss: 0.717  训练集准确率: 87.88%  验证集准确率: 43.99%\n",
      "Epoch [19/50] [19992/35792]  Loss: 0.532  训练集准确率: 87.79%  验证集准确率: 50.67%\n",
      "Epoch [19/50] [23992/35792]  Loss: 0.475  训练集准确率: 87.97%  验证集准确率: 50.27%\n",
      "Epoch [19/50] [27992/35792]  Loss: 0.447  训练集准确率: 87.97%  验证集准确率: 41.03%\n",
      "Epoch [19/50] [31992/35792]  Loss: 0.488  训练集准确率: 87.83%  验证集准确率: 46.90%\n",
      "Epoch [20/50] [3992/35792]  Loss: 0.822  训练集准确率: 88.10%  验证集准确率: 46.76%\n",
      "Epoch [20/50] [7992/35792]  Loss: 0.914  训练集准确率: 88.16%  验证集准确率: 31.85%\n",
      "Epoch [20/50] [11992/35792]  Loss: 0.449  训练集准确率: 87.78%  验证集准确率: 44.20%\n",
      "Epoch [20/50] [15992/35792]  Loss: 0.447  训练集准确率: 87.93%  验证集准确率: 44.87%\n",
      "Epoch [20/50] [19992/35792]  Loss: 1.157  训练集准确率: 87.83%  验证集准确率: 47.98%\n",
      "Epoch [20/50] [23992/35792]  Loss: 0.448  训练集准确率: 87.97%  验证集准确率: 43.66%\n",
      "Epoch [20/50] [27992/35792]  Loss: 0.577  训练集准确率: 87.92%  验证集准确率: 47.23%\n",
      "Epoch [20/50] [31992/35792]  Loss: 0.446  训练集准确率: 87.91%  验证集准确率: 46.36%\n",
      "Epoch [21/50] [3992/35792]  Loss: 0.450  训练集准确率: 88.00%  验证集准确率: 41.36%\n",
      "Epoch [21/50] [7992/35792]  Loss: 0.448  训练集准确率: 88.07%  验证集准确率: 47.10%\n",
      "Epoch [21/50] [11992/35792]  Loss: 0.822  训练集准确率: 88.13%  验证集准确率: 48.72%\n",
      "Epoch [21/50] [15992/35792]  Loss: 1.076  训练集准确率: 88.11%  验证集准确率: 44.47%\n",
      "Epoch [21/50] [19992/35792]  Loss: 1.480  训练集准确率: 88.00%  验证集准确率: 48.99%\n",
      "Epoch [21/50] [23992/35792]  Loss: 0.450  训练集准确率: 87.94%  验证集准确率: 47.44%\n",
      "Epoch [21/50] [27992/35792]  Loss: 0.793  训练集准确率: 87.96%  验证集准确率: 40.62%\n",
      "Epoch [21/50] [31992/35792]  Loss: 0.541  训练集准确率: 87.94%  验证集准确率: 44.60%\n",
      "Epoch [22/50] [3992/35792]  Loss: 0.467  训练集准确率: 88.68%  验证集准确率: 37.99%\n",
      "Epoch [22/50] [7992/35792]  Loss: 0.620  训练集准确率: 88.62%  验证集准确率: 48.58%\n",
      "Epoch [22/50] [11992/35792]  Loss: 0.686  训练集准确率: 88.28%  验证集准确率: 45.28%\n",
      "Epoch [22/50] [15992/35792]  Loss: 0.603  训练集准确率: 88.23%  验证集准确率: 46.22%\n",
      "Epoch [22/50] [19992/35792]  Loss: 0.556  训练集准确率: 88.11%  验证集准确率: 36.98%\n",
      "Epoch [22/50] [23992/35792]  Loss: 0.441  训练集准确率: 88.07%  验证集准确率: 49.12%\n",
      "Epoch [22/50] [27992/35792]  Loss: 0.463  训练集准确率: 88.05%  验证集准确率: 42.91%\n",
      "Epoch [22/50] [31992/35792]  Loss: 0.449  训练集准确率: 88.02%  验证集准确率: 44.94%\n",
      "Epoch [23/50] [3992/35792]  Loss: 0.787  训练集准确率: 88.35%  验证集准确率: 39.20%\n",
      "Epoch [23/50] [7992/35792]  Loss: 0.557  训练集准确率: 88.34%  验证集准确率: 48.31%\n",
      "Epoch [23/50] [11992/35792]  Loss: 0.912  训练集准确率: 88.43%  验证集准确率: 45.28%\n",
      "Epoch [23/50] [15992/35792]  Loss: 0.483  训练集准确率: 88.47%  验证集准确率: 49.26%\n",
      "Epoch [23/50] [19992/35792]  Loss: 1.046  训练集准确率: 88.32%  验证集准确率: 50.34%\n",
      "Epoch [23/50] [23992/35792]  Loss: 0.538  训练集准确率: 88.46%  验证集准确率: 46.36%\n",
      "Epoch [23/50] [27992/35792]  Loss: 0.451  训练集准确率: 88.41%  验证集准确率: 46.22%\n",
      "Epoch [23/50] [31992/35792]  Loss: 0.667  训练集准确率: 88.38%  验证集准确率: 46.69%\n",
      "Epoch [24/50] [3992/35792]  Loss: 0.545  训练集准确率: 88.57%  验证集准确率: 43.72%\n",
      "Epoch [24/50] [7992/35792]  Loss: 0.437  训练集准确率: 88.60%  验证集准确率: 41.03%\n",
      "Epoch [24/50] [11992/35792]  Loss: 0.480  训练集准确率: 88.24%  验证集准确率: 42.98%\n",
      "Epoch [24/50] [15992/35792]  Loss: 0.509  训练集准确率: 87.95%  验证集准确率: 42.17%\n",
      "Epoch [24/50] [19992/35792]  Loss: 0.445  训练集准确率: 87.96%  验证集准确率: 46.22%\n",
      "Epoch [24/50] [23992/35792]  Loss: 0.949  训练集准确率: 87.94%  验证集准确率: 45.34%\n",
      "Epoch [24/50] [27992/35792]  Loss: 0.712  训练集准确率: 87.80%  验证集准确率: 45.41%\n",
      "Epoch [24/50] [31992/35792]  Loss: 0.737  训练集准确率: 87.80%  验证集准确率: 50.34%\n",
      "Epoch [25/50] [3992/35792]  Loss: 0.857  训练集准确率: 88.25%  验证集准确率: 52.50%\n",
      "Epoch [25/50] [7992/35792]  Loss: 0.452  训练集准确率: 88.11%  验证集准确率: 48.18%\n",
      "Epoch [25/50] [11992/35792]  Loss: 0.448  训练集准确率: 88.12%  验证集准确率: 46.96%\n",
      "Epoch [25/50] [15992/35792]  Loss: 0.486  训练集准确率: 88.13%  验证集准确率: 53.44%\n",
      "Epoch [25/50] [19992/35792]  Loss: 0.910  训练集准确率: 88.14%  验证集准确率: 43.99%\n",
      "Epoch [25/50] [23992/35792]  Loss: 0.967  训练集准确率: 88.08%  验证集准确率: 42.91%\n",
      "Epoch [25/50] [27992/35792]  Loss: 0.448  训练集准确率: 88.06%  验证集准确率: 40.42%\n",
      "Epoch [25/50] [31992/35792]  Loss: 0.449  训练集准确率: 88.09%  验证集准确率: 45.82%\n",
      "Epoch [26/50] [3992/35792]  Loss: 0.759  训练集准确率: 88.38%  验证集准确率: 53.31%\n",
      "Epoch [26/50] [7992/35792]  Loss: 0.756  训练集准确率: 88.16%  验证集准确率: 45.01%\n",
      "Epoch [26/50] [11992/35792]  Loss: 0.642  训练集准确率: 88.19%  验证集准确率: 48.04%\n",
      "Epoch [26/50] [15992/35792]  Loss: 0.723  训练集准确率: 88.33%  验证集准确率: 48.92%\n",
      "Epoch [26/50] [19992/35792]  Loss: 0.787  训练集准确率: 88.32%  验证集准确率: 51.42%\n",
      "Epoch [26/50] [23992/35792]  Loss: 0.449  训练集准确率: 88.36%  验证集准确率: 50.00%\n",
      "Epoch [26/50] [27992/35792]  Loss: 1.467  训练集准确率: 88.39%  验证集准确率: 37.65%\n",
      "Epoch [26/50] [31992/35792]  Loss: 1.367  训练集准确率: 88.38%  验证集准确率: 51.48%\n",
      "Epoch [27/50] [3992/35792]  Loss: 2.487  训练集准确率: 88.10%  验证集准确率: 46.63%\n",
      "Epoch [27/50] [7992/35792]  Loss: 1.529  训练集准确率: 87.96%  验证集准确率: 41.70%\n",
      "Epoch [27/50] [11992/35792]  Loss: 0.554  训练集准确率: 88.03%  验证集准确率: 39.74%\n",
      "Epoch [27/50] [15992/35792]  Loss: 0.826  训练集准确率: 87.97%  验证集准确率: 48.45%\n",
      "Epoch [27/50] [19992/35792]  Loss: 0.546  训练集准确率: 88.15%  验证集准确率: 48.45%\n",
      "Epoch [27/50] [23992/35792]  Loss: 0.448  训练集准确率: 88.19%  验证集准确率: 46.29%\n",
      "Epoch [27/50] [27992/35792]  Loss: 1.061  训练集准确率: 88.26%  验证集准确率: 46.49%\n",
      "Epoch [27/50] [31992/35792]  Loss: 1.146  训练集准确率: 88.21%  验证集准确率: 44.53%\n",
      "Epoch [28/50] [3992/35792]  Loss: 0.601  训练集准确率: 88.47%  验证集准确率: 47.50%\n",
      "Epoch [28/50] [7992/35792]  Loss: 0.455  训练集准确率: 88.82%  验证集准确率: 44.33%\n",
      "Epoch [28/50] [11992/35792]  Loss: 0.448  训练集准确率: 88.61%  验证集准确率: 48.58%\n",
      "Epoch [28/50] [15992/35792]  Loss: 0.571  训练集准确率: 88.50%  验证集准确率: 46.49%\n",
      "Epoch [28/50] [19992/35792]  Loss: 0.532  训练集准确率: 88.51%  验证集准确率: 44.67%\n",
      "Epoch [28/50] [23992/35792]  Loss: 0.549  训练集准确率: 88.49%  验证集准确率: 45.48%\n",
      "Epoch [28/50] [27992/35792]  Loss: 0.448  训练集准确率: 88.50%  验证集准确率: 45.61%\n",
      "Epoch [28/50] [31992/35792]  Loss: 0.836  训练集准确率: 88.54%  验证集准确率: 43.99%\n",
      "Epoch [29/50] [3992/35792]  Loss: 0.537  训练集准确率: 87.93%  验证集准确率: 45.61%\n",
      "Epoch [29/50] [7992/35792]  Loss: 0.622  训练集准确率: 87.99%  验证集准确率: 46.76%\n",
      "Epoch [29/50] [11992/35792]  Loss: 0.441  训练集准确率: 88.25%  验证集准确率: 41.43%\n",
      "Epoch [29/50] [15992/35792]  Loss: 0.448  训练集准确率: 88.54%  验证集准确率: 46.36%\n",
      "Epoch [29/50] [19992/35792]  Loss: 0.636  训练集准确率: 88.42%  验证集准确率: 51.89%\n",
      "Epoch [29/50] [23992/35792]  Loss: 0.732  训练集准确率: 88.31%  验证集准确率: 44.26%\n",
      "Epoch [29/50] [27992/35792]  Loss: 0.453  训练集准确率: 88.35%  验证集准确率: 51.55%\n",
      "Epoch [29/50] [31992/35792]  Loss: 0.882  训练集准确率: 88.26%  验证集准确率: 45.01%\n",
      "Epoch [30/50] [3992/35792]  Loss: 0.819  训练集准确率: 88.85%  验证集准确率: 46.83%\n",
      "Epoch [30/50] [7992/35792]  Loss: 0.685  训练集准确率: 88.59%  验证集准确率: 54.05%\n",
      "Epoch [30/50] [11992/35792]  Loss: 0.698  训练集准确率: 88.53%  验证集准确率: 46.69%\n",
      "Epoch [30/50] [15992/35792]  Loss: 0.620  训练集准确率: 88.47%  验证集准确率: 44.67%\n",
      "Epoch [30/50] [19992/35792]  Loss: 0.512  训练集准确率: 88.43%  验证集准确率: 36.17%\n",
      "Epoch [30/50] [23992/35792]  Loss: 0.496  训练集准确率: 88.34%  验证集准确率: 49.39%\n",
      "Epoch [30/50] [27992/35792]  Loss: 0.666  训练集准确率: 88.32%  验证集准确率: 47.17%\n",
      "Epoch [30/50] [31992/35792]  Loss: 0.880  训练集准确率: 88.26%  验证集准确率: 47.44%\n",
      "Epoch [31/50] [3992/35792]  Loss: 0.530  训练集准确率: 88.65%  验证集准确率: 54.05%\n",
      "Epoch [31/50] [7992/35792]  Loss: 0.719  训练集准确率: 88.60%  验证集准确率: 47.30%\n",
      "Epoch [31/50] [11992/35792]  Loss: 0.810  训练集准确率: 88.80%  验证集准确率: 46.22%\n",
      "Epoch [31/50] [15992/35792]  Loss: 0.449  训练集准确率: 88.78%  验证集准确率: 49.73%\n",
      "Epoch [31/50] [19992/35792]  Loss: 0.471  训练集准确率: 88.77%  验证集准确率: 48.45%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/50] [23992/35792]  Loss: 0.549  训练集准确率: 88.64%  验证集准确率: 43.52%\n",
      "Epoch [31/50] [27992/35792]  Loss: 0.448  训练集准确率: 88.59%  验证集准确率: 46.83%\n",
      "Epoch [31/50] [31992/35792]  Loss: 0.675  训练集准确率: 88.60%  验证集准确率: 36.57%\n",
      "Epoch [32/50] [3992/35792]  Loss: 0.446  训练集准确率: 88.38%  验证集准确率: 37.52%\n",
      "Epoch [32/50] [7992/35792]  Loss: 0.455  训练集准确率: 88.46%  验证集准确率: 45.14%\n",
      "Epoch [32/50] [11992/35792]  Loss: 0.640  训练集准确率: 88.51%  验证集准确率: 43.12%\n",
      "Epoch [32/50] [15992/35792]  Loss: 0.468  训练集准确率: 88.43%  验证集准确率: 50.61%\n",
      "Epoch [32/50] [19992/35792]  Loss: 0.694  训练集准确率: 88.50%  验证集准确率: 48.18%\n",
      "Epoch [32/50] [23992/35792]  Loss: 1.260  训练集准确率: 88.57%  验证集准确率: 47.30%\n",
      "Epoch [32/50] [27992/35792]  Loss: 0.454  训练集准确率: 88.55%  验证集准确率: 45.01%\n",
      "Epoch [32/50] [31992/35792]  Loss: 0.440  训练集准确率: 88.54%  验证集准确率: 43.79%\n",
      "Epoch [33/50] [3992/35792]  Loss: 0.494  训练集准确率: 87.47%  验证集准确率: 43.93%\n",
      "Epoch [33/50] [7992/35792]  Loss: 0.683  训练集准确率: 88.10%  验证集准确率: 41.03%\n",
      "Epoch [33/50] [11992/35792]  Loss: 0.445  训练集准确率: 88.35%  验证集准确率: 48.11%\n",
      "Epoch [33/50] [15992/35792]  Loss: 0.466  训练集准确率: 88.26%  验证集准确率: 48.58%\n",
      "Epoch [33/50] [19992/35792]  Loss: 1.225  训练集准确率: 88.25%  验证集准确率: 42.71%\n",
      "Epoch [33/50] [23992/35792]  Loss: 0.507  训练集准确率: 88.28%  验证集准确率: 47.44%\n",
      "Epoch [33/50] [27992/35792]  Loss: 1.096  训练集准确率: 88.33%  验证集准确率: 36.98%\n",
      "Epoch [33/50] [31992/35792]  Loss: 0.481  训练集准确率: 88.32%  验证集准确率: 38.53%\n",
      "Epoch [34/50] [3992/35792]  Loss: 0.676  训练集准确率: 88.53%  验证集准确率: 40.69%\n",
      "Epoch [34/50] [7992/35792]  Loss: 0.466  训练集准确率: 88.59%  验证集准确率: 35.63%\n",
      "Epoch [34/50] [11992/35792]  Loss: 0.448  训练集准确率: 88.62%  验证集准确率: 46.42%\n",
      "Epoch [34/50] [15992/35792]  Loss: 0.448  训练集准确率: 88.68%  验证集准确率: 39.88%\n",
      "Epoch [34/50] [19992/35792]  Loss: 0.610  训练集准确率: 88.72%  验证集准确率: 34.08%\n",
      "Epoch [34/50] [23992/35792]  Loss: 0.494  训练集准确率: 88.70%  验证集准确率: 45.07%\n",
      "Epoch [34/50] [27992/35792]  Loss: 0.450  训练集准确率: 88.61%  验证集准确率: 35.56%\n",
      "Epoch [34/50] [31992/35792]  Loss: 0.448  训练集准确率: 88.60%  验证集准确率: 38.87%\n",
      "Epoch [35/50] [3992/35792]  Loss: 0.469  训练集准确率: 88.80%  验证集准确率: 42.98%\n",
      "Epoch [35/50] [7992/35792]  Loss: 0.446  训练集准确率: 88.95%  验证集准确率: 42.31%\n",
      "Epoch [35/50] [11992/35792]  Loss: 0.611  训练集准确率: 88.76%  验证集准确率: 43.59%\n",
      "Epoch [35/50] [15992/35792]  Loss: 0.961  训练集准确率: 88.62%  验证集准确率: 39.74%\n",
      "Epoch [35/50] [19992/35792]  Loss: 0.448  训练集准确率: 88.54%  验证集准确率: 44.80%\n",
      "Epoch [35/50] [23992/35792]  Loss: 0.633  训练集准确率: 88.50%  验证集准确率: 43.25%\n",
      "Epoch [35/50] [27992/35792]  Loss: 0.449  训练集准确率: 88.42%  验证集准确率: 41.90%\n",
      "Epoch [35/50] [31992/35792]  Loss: 0.464  训练集准确率: 88.48%  验证集准确率: 46.42%\n",
      "Epoch [36/50] [3992/35792]  Loss: 0.794  训练集准确率: 88.28%  验证集准确率: 40.69%\n",
      "Epoch [36/50] [7992/35792]  Loss: 0.441  训练集准确率: 88.24%  验证集准确率: 43.39%\n",
      "Epoch [36/50] [11992/35792]  Loss: 0.664  训练集准确率: 88.47%  验证集准确率: 41.03%\n",
      "Epoch [36/50] [15992/35792]  Loss: 0.894  训练集准确率: 88.48%  验证集准确率: 43.66%\n",
      "Epoch [36/50] [19992/35792]  Loss: 0.448  训练集准确率: 88.49%  验证集准确率: 45.75%\n",
      "Epoch [36/50] [23992/35792]  Loss: 0.663  训练集准确率: 88.57%  验证集准确率: 38.19%\n",
      "Epoch [36/50] [27992/35792]  Loss: 0.448  训练集准确率: 88.52%  验证集准确率: 42.38%\n",
      "Epoch [36/50] [31992/35792]  Loss: 0.448  训练集准确率: 88.49%  验证集准确率: 39.27%\n",
      "Epoch [37/50] [3992/35792]  Loss: 0.580  训练集准确率: 88.85%  验证集准确率: 33.54%\n",
      "Epoch [37/50] [7992/35792]  Loss: 0.727  训练集准确率: 88.88%  验证集准确率: 42.31%\n",
      "Epoch [37/50] [11992/35792]  Loss: 0.447  训练集准确率: 88.75%  验证集准确率: 45.21%\n",
      "Epoch [37/50] [15992/35792]  Loss: 0.493  训练集准确率: 88.57%  验证集准确率: 32.19%\n",
      "Epoch [37/50] [19992/35792]  Loss: 0.627  训练集准确率: 88.64%  验证集准确率: 45.61%\n",
      "Epoch [37/50] [23992/35792]  Loss: 0.754  训练集准确率: 88.52%  验证集准确率: 42.31%\n",
      "Epoch [37/50] [27992/35792]  Loss: 0.709  训练集准确率: 88.57%  验证集准确率: 42.44%\n",
      "Epoch [37/50] [31992/35792]  Loss: 0.873  训练集准确率: 88.56%  验证集准确率: 45.14%\n",
      "Epoch [38/50] [3992/35792]  Loss: 0.608  训练集准确率: 88.20%  验证集准确率: 46.09%\n",
      "Epoch [38/50] [7992/35792]  Loss: 2.018  训练集准确率: 87.94%  验证集准确率: 36.77%\n",
      "Epoch [38/50] [11992/35792]  Loss: 0.886  训练集准确率: 88.28%  验证集准确率: 48.04%\n",
      "Epoch [38/50] [15992/35792]  Loss: 0.620  训练集准确率: 88.44%  验证集准确率: 49.66%\n",
      "Epoch [38/50] [19992/35792]  Loss: 0.447  训练集准确率: 88.67%  验证集准确率: 51.21%\n",
      "Epoch [38/50] [23992/35792]  Loss: 1.029  训练集准确率: 88.63%  验证集准确率: 42.17%\n",
      "Epoch [38/50] [27992/35792]  Loss: 0.448  训练集准确率: 88.67%  验证集准确率: 49.93%\n",
      "Epoch [38/50] [31992/35792]  Loss: 0.506  训练集准确率: 88.76%  验证集准确率: 42.04%\n",
      "Epoch [39/50] [3992/35792]  Loss: 0.999  训练集准确率: 89.18%  验证集准确率: 42.51%\n",
      "Epoch [39/50] [7992/35792]  Loss: 0.754  训练集准确率: 88.70%  验证集准确率: 46.36%\n",
      "Epoch [39/50] [11992/35792]  Loss: 0.674  训练集准确率: 88.73%  验证集准确率: 37.72%\n",
      "Epoch [39/50] [15992/35792]  Loss: 0.707  训练集准确率: 88.76%  验证集准确率: 46.02%\n",
      "Epoch [39/50] [19992/35792]  Loss: 1.114  训练集准确率: 88.63%  验证集准确率: 43.05%\n",
      "Epoch [39/50] [23992/35792]  Loss: 0.960  训练集准确率: 88.71%  验证集准确率: 45.48%\n",
      "Epoch [39/50] [27992/35792]  Loss: 0.452  训练集准确率: 88.79%  验证集准确率: 43.39%\n",
      "Epoch [39/50] [31992/35792]  Loss: 0.498  训练集准确率: 88.73%  验证集准确率: 49.73%\n",
      "Epoch [40/50] [3992/35792]  Loss: 0.829  训练集准确率: 89.43%  验证集准确率: 46.90%\n",
      "Epoch [40/50] [7992/35792]  Loss: 0.718  训练集准确率: 89.39%  验证集准确率: 47.50%\n",
      "Epoch [40/50] [11992/35792]  Loss: 0.452  训练集准确率: 89.40%  验证集准确率: 35.56%\n",
      "Epoch [40/50] [15992/35792]  Loss: 0.943  训练集准确率: 89.16%  验证集准确率: 40.69%\n",
      "Epoch [40/50] [19992/35792]  Loss: 0.887  训练集准确率: 88.94%  验证集准确率: 38.66%\n",
      "Epoch [40/50] [23992/35792]  Loss: 0.448  训练集准确率: 88.98%  验证集准确率: 30.97%\n",
      "Epoch [40/50] [27992/35792]  Loss: 0.449  训练集准确率: 88.94%  验证集准确率: 49.19%\n",
      "Epoch [40/50] [31992/35792]  Loss: 0.445  训练集准确率: 88.84%  验证集准确率: 52.90%\n",
      "Epoch [41/50] [3992/35792]  Loss: 0.801  训练集准确率: 89.00%  验证集准确率: 50.54%\n",
      "Epoch [41/50] [7992/35792]  Loss: 0.685  训练集准确率: 89.38%  验证集准确率: 50.88%\n",
      "Epoch [41/50] [11992/35792]  Loss: 0.449  训练集准确率: 89.17%  验证集准确率: 49.26%\n",
      "Epoch [41/50] [15992/35792]  Loss: 0.533  训练集准确率: 89.01%  验证集准确率: 47.84%\n",
      "Epoch [41/50] [19992/35792]  Loss: 0.851  训练集准确率: 88.92%  验证集准确率: 44.06%\n",
      "Epoch [41/50] [23992/35792]  Loss: 0.686  训练集准确率: 88.92%  验证集准确率: 44.26%\n",
      "Epoch [41/50] [27992/35792]  Loss: 0.720  训练集准确率: 88.99%  验证集准确率: 37.85%\n",
      "Epoch [41/50] [31992/35792]  Loss: 0.485  训练集准确率: 88.97%  验证集准确率: 45.01%\n",
      "Epoch [42/50] [3992/35792]  Loss: 0.444  训练集准确率: 88.45%  验证集准确率: 48.52%\n",
      "Epoch [42/50] [7992/35792]  Loss: 0.706  训练集准确率: 88.53%  验证集准确率: 46.83%\n",
      "Epoch [42/50] [11992/35792]  Loss: 0.453  训练集准确率: 88.53%  验证集准确率: 48.25%\n",
      "Epoch [42/50] [15992/35792]  Loss: 0.655  训练集准确率: 88.50%  验证集准确率: 40.42%\n",
      "Epoch [42/50] [19992/35792]  Loss: 0.451  训练集准确率: 88.61%  验证集准确率: 40.62%\n",
      "Epoch [42/50] [23992/35792]  Loss: 0.448  训练集准确率: 88.72%  验证集准确率: 43.99%\n",
      "Epoch [42/50] [27992/35792]  Loss: 1.760  训练集准确率: 88.77%  验证集准确率: 43.05%\n",
      "Epoch [42/50] [31992/35792]  Loss: 0.448  训练集准确率: 88.80%  验证集准确率: 41.70%\n",
      "Epoch [43/50] [3992/35792]  Loss: 0.445  训练集准确率: 87.93%  验证集准确率: 46.83%\n",
      "Epoch [43/50] [7992/35792]  Loss: 1.580  训练集准确率: 88.49%  验证集准确率: 41.09%\n",
      "Epoch [43/50] [11992/35792]  Loss: 0.448  训练集准确率: 88.52%  验证集准确率: 38.12%\n",
      "Epoch [43/50] [15992/35792]  Loss: 1.047  训练集准确率: 88.31%  验证集准确率: 47.91%\n",
      "Epoch [43/50] [19992/35792]  Loss: 0.753  训练集准确率: 88.43%  验证集准确率: 43.59%\n",
      "Epoch [43/50] [23992/35792]  Loss: 0.867  训练集准确率: 88.53%  验证集准确率: 43.05%\n",
      "Epoch [43/50] [27992/35792]  Loss: 0.446  训练集准确率: 88.50%  验证集准确率: 51.15%\n",
      "Epoch [43/50] [31992/35792]  Loss: 0.491  训练集准确率: 88.44%  验证集准确率: 42.44%\n",
      "Epoch [44/50] [3992/35792]  Loss: 0.448  训练集准确率: 89.12%  验证集准确率: 40.89%\n",
      "Epoch [44/50] [7992/35792]  Loss: 0.586  训练集准确率: 89.28%  验证集准确率: 27.06%\n",
      "Epoch [44/50] [11992/35792]  Loss: 0.924  训练集准确率: 89.21%  验证集准确率: 41.36%\n",
      "Epoch [44/50] [15992/35792]  Loss: 0.448  训练集准确率: 88.91%  验证集准确率: 41.70%\n",
      "Epoch [44/50] [19992/35792]  Loss: 0.461  训练集准确率: 89.04%  验证集准确率: 44.74%\n",
      "Epoch [44/50] [23992/35792]  Loss: 0.815  训练集准确率: 88.93%  验证集准确率: 42.17%\n",
      "Epoch [44/50] [27992/35792]  Loss: 0.709  训练集准确率: 88.92%  验证集准确率: 46.22%\n",
      "Epoch [44/50] [31992/35792]  Loss: 0.448  训练集准确率: 88.88%  验证集准确率: 43.45%\n",
      "Epoch [45/50] [3992/35792]  Loss: 0.814  训练集准确率: 89.82%  验证集准确率: 46.15%\n",
      "Epoch [45/50] [7992/35792]  Loss: 0.726  训练集准确率: 89.22%  验证集准确率: 45.21%\n",
      "Epoch [45/50] [11992/35792]  Loss: 0.523  训练集准确率: 89.35%  验证集准确率: 39.07%\n",
      "Epoch [45/50] [15992/35792]  Loss: 0.504  训练集准确率: 89.16%  验证集准确率: 45.01%\n",
      "Epoch [45/50] [19992/35792]  Loss: 0.473  训练集准确率: 89.02%  验证集准确率: 49.60%\n",
      "Epoch [45/50] [23992/35792]  Loss: 0.558  训练集准确率: 89.05%  验证集准确率: 52.97%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/50] [27992/35792]  Loss: 1.013  训练集准确率: 88.99%  验证集准确率: 47.10%\n",
      "Epoch [45/50] [31992/35792]  Loss: 1.423  训练集准确率: 89.05%  验证集准确率: 39.00%\n",
      "Epoch [46/50] [3992/35792]  Loss: 0.448  训练集准确率: 88.68%  验证集准确率: 47.30%\n",
      "Epoch [46/50] [7992/35792]  Loss: 0.694  训练集准确率: 89.26%  验证集准确率: 48.11%\n",
      "Epoch [46/50] [11992/35792]  Loss: 0.448  训练集准确率: 89.27%  验证集准确率: 50.27%\n",
      "Epoch [46/50] [15992/35792]  Loss: 0.445  训练集准确率: 89.13%  验证集准确率: 50.40%\n",
      "Epoch [46/50] [19992/35792]  Loss: 1.290  训练集准确率: 89.10%  验证集准确率: 39.27%\n",
      "Epoch [46/50] [23992/35792]  Loss: 0.487  训练集准确率: 89.11%  验证集准确率: 38.53%\n",
      "Epoch [46/50] [27992/35792]  Loss: 0.448  训练集准确率: 89.10%  验证集准确率: 47.10%\n",
      "Epoch [46/50] [31992/35792]  Loss: 0.448  训练集准确率: 89.16%  验证集准确率: 37.58%\n",
      "Epoch [47/50] [3992/35792]  Loss: 0.480  训练集准确率: 89.28%  验证集准确率: 48.85%\n",
      "Epoch [47/50] [7992/35792]  Loss: 0.528  训练集准确率: 89.09%  验证集准确率: 49.60%\n",
      "Epoch [47/50] [11992/35792]  Loss: 1.618  训练集准确率: 89.02%  验证集准确率: 39.34%\n",
      "Epoch [47/50] [15992/35792]  Loss: 0.459  训练集准确率: 88.96%  验证集准确率: 50.47%\n",
      "Epoch [47/50] [19992/35792]  Loss: 0.448  训练集准确率: 89.06%  验证集准确率: 44.26%\n",
      "Epoch [47/50] [23992/35792]  Loss: 0.429  训练集准确率: 89.13%  验证集准确率: 44.74%\n",
      "Epoch [47/50] [27992/35792]  Loss: 0.448  训练集准确率: 89.16%  验证集准确率: 48.65%\n",
      "Epoch [47/50] [31992/35792]  Loss: 0.732  训练集准确率: 89.12%  验证集准确率: 52.29%\n",
      "Epoch [48/50] [3992/35792]  Loss: 0.827  训练集准确率: 88.50%  验证集准确率: 54.86%\n",
      "Epoch [48/50] [7992/35792]  Loss: 0.473  训练集准确率: 88.65%  验证集准确率: 53.98%\n",
      "Epoch [48/50] [11992/35792]  Loss: 0.445  训练集准确率: 88.64%  验证集准确率: 50.34%\n",
      "Epoch [48/50] [15992/35792]  Loss: 0.448  训练集准确率: 88.66%  验证集准确率: 47.98%\n",
      "Epoch [48/50] [19992/35792]  Loss: 0.910  训练集准确率: 88.75%  验证集准确率: 48.65%\n",
      "Epoch [48/50] [23992/35792]  Loss: 0.458  训练集准确率: 88.88%  验证集准确率: 46.02%\n",
      "Epoch [48/50] [27992/35792]  Loss: 0.447  训练集准确率: 88.95%  验证集准确率: 52.90%\n",
      "Epoch [48/50] [31992/35792]  Loss: 0.448  训练集准确率: 88.94%  验证集准确率: 52.70%\n",
      "Epoch [49/50] [3992/35792]  Loss: 0.446  训练集准确率: 89.47%  验证集准确率: 52.83%\n",
      "Epoch [49/50] [7992/35792]  Loss: 0.466  训练集准确率: 89.28%  验证集准确率: 44.87%\n",
      "Epoch [49/50] [11992/35792]  Loss: 0.468  训练集准确率: 89.06%  验证集准确率: 43.86%\n",
      "Epoch [49/50] [15992/35792]  Loss: 0.504  训练集准确率: 89.04%  验证集准确率: 45.34%\n",
      "Epoch [49/50] [19992/35792]  Loss: 0.468  训练集准确率: 89.04%  验证集准确率: 43.05%\n",
      "Epoch [49/50] [23992/35792]  Loss: 0.448  训练集准确率: 89.06%  验证集准确率: 42.85%\n",
      "Epoch [49/50] [27992/35792]  Loss: 0.444  训练集准确率: 88.90%  验证集准确率: 46.42%\n",
      "Epoch [49/50] [31992/35792]  Loss: 0.743  训练集准确率: 88.84%  验证集准确率: 49.80%\n",
      "Epoch [50/50] [3992/35792]  Loss: 0.828  训练集准确率: 89.12%  验证集准确率: 38.19%\n",
      "Epoch [50/50] [7992/35792]  Loss: 0.750  训练集准确率: 89.03%  验证集准确率: 44.40%\n",
      "Epoch [50/50] [11992/35792]  Loss: 0.449  训练集准确率: 88.78%  验证集准确率: 50.47%\n",
      "Epoch [50/50] [15992/35792]  Loss: 0.711  训练集准确率: 88.73%  验证集准确率: 51.35%\n",
      "Epoch [50/50] [19992/35792]  Loss: 0.739  训练集准确率: 88.79%  验证集准确率: 50.20%\n",
      "Epoch [50/50] [23992/35792]  Loss: 0.448  训练集准确率: 88.72%  验证集准确率: 47.98%\n",
      "Epoch [50/50] [27992/35792]  Loss: 0.693  训练集准确率: 88.64%  验证集准确率: 45.41%\n",
      "Epoch [50/50] [31992/35792]  Loss: 0.608  训练集准确率: 88.67%  验证集准确率: 45.28%\n"
     ]
    }
   ],
   "source": [
    "net = ConvNet()\n",
    "# net.to(device)\n",
    "criterion = nn.CrossEntropyLoss() #Loss函数的定义，交叉熵\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9) #定义优化器，普通的随机梯度下降算法\n",
    "\n",
    "record = [] #记录训练集和验证集上错误率的list\n",
    "weights = [] #每若干步就记录一次卷积核\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_accuracy = [] #记录训练数据集准确率的容器\n",
    "    # 一次迭代一个batch的 data 和 target\n",
    "    for batch_id, (data,target) in enumerate(train_loader):\n",
    "#         data = data.to(device)\n",
    "#         target = target.to(device)\n",
    "        net.train() # 给网络模型做标记，打开关闭net的training标志,从而决定是否运行dropout\n",
    "        output =  net(data) #forward  \n",
    "        loss = criterion(output, target) \n",
    "#         print(batch_id,\":loss \",loss)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()   #反向传播\n",
    "        optimizer.step()  #更新权重\n",
    "        \n",
    "        accuracies = accuracy(output, target)\n",
    "#         print(\"output:\",output)\n",
    "#         print(\"target\",target)\n",
    "        train_accuracy.append(accuracies)\n",
    "#         print(batch_id,\"acc:\",accuracies)\n",
    "        if batch_id% 500 ==499: #每间隔100个batch执行一次打印等操作\n",
    "            net.eval() # 给网络模型做标记，将模型转换为测试模式。\n",
    "            val_accuracy = [] #记录校验数据集准确率的容器\n",
    "            \n",
    "            for (data, target) in validation_loader: #计算校验集上面的准确度\n",
    "                output = net(data) #完成一次前馈计算过程，得到目前训练得到的模型net在校验数据集上的表现\n",
    "                accuracies = accuracy(output, target) #计算准确率所需数值，返回正确的数值为（正确样例数，总样本数）\n",
    "                val_accuracy.append(accuracies)\n",
    "                \n",
    "            # 分别计算在已经计算过的训练集，以及全部校验集上模型的分类准确率\n",
    "            \n",
    "            #train_r为一个二元组，分别记录目前  已经经历过的所有  训练集中分类正确的数量和该集合中总的样本数，\n",
    "            train_r = (sum([tup[0] for tup in train_accuracy]), sum([tup[1] for tup in train_accuracy]))\n",
    "            #val_r为一个二元组，分别记录校验集中分类正确的数量和该集合中总的样本数\n",
    "            val_r = (sum([tup[0] for tup in val_accuracy]), sum([tup[1] for tup in val_accuracy]))\n",
    "            \n",
    "            #打印准确率等数值，其中正确率为本训练周期Epoch开始后到目前batch的正确率的平均值\n",
    "            print('Epoch [{}/{}] [{}/{}]  Loss: {:.3f}  训练集准确率: {:.2f}%  验证集准确率: {:.2f}%'.format(\n",
    "                epoch+1,num_epochs, batch_id * batch_size, len(train_loader.dataset),\n",
    "                loss.item(), \n",
    "                100 * train_r[0] / train_r[1], \n",
    "                100 * val_r[0] / val_r[1]))\n",
    "            \n",
    "            #将准确率和权重等数值加载到容器中，方便后续处理\n",
    "            \n",
    "            record.append((100 - 100 * train_r[0] / train_r[1],100 - 100 * val_r[0] / val_r[1]))\n",
    "            \n",
    "            # weights记录了训练周期中所有卷积核的演化过程。net.conv1.weight就提取出了第一层卷积核的权重\n",
    "            # clone的意思就是将weight.data中的数据做一个拷贝放到列表中，否则当weight.data变化的时候，列表中的每一项数值也会联动\n",
    "            '''这里使用clone这个函数很重要'''\n",
    "            weights.append([net.conv1.weight.data.clone(), net.conv1.bias.data.clone(), \n",
    "                            net.conv2.weight.data.clone(), net.conv2.bias.data.clone()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy is 0.0088\n"
     ]
    }
   ],
   "source": [
    "accuracy_test(net,test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 全连接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.l1 = torch.nn.Linear(1024,512)\n",
    "        self.l2 = torch.nn.Linear(512,256)\n",
    "        self.l3 = torch.nn.Linear(256,128)\n",
    "        self.l4 = torch.nn.Linear(128,64)\n",
    "        self.l5 = torch.nn.Linear(64,36)\n",
    "    def forward(self,x):\n",
    "        x = x.view(-1,1024)\n",
    "        x = F.relu(self.l1(x))\n",
    "        x = F.relu(self.l2(x))\n",
    "        x = F.relu(self.l3(x))\n",
    "        x = F.relu(self.l4(x))\n",
    "        return self.l5(x)\n",
    "model = Net()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch,train_loader):\n",
    "    criterion = torch.nn.CrossEntropyLoss() #损失函数 为交叉熵\n",
    "    optimizer = optim.SGD(model.parameters(),lr = 0.01,momentum=0.5) #优化器\n",
    "    running_loss = 0.0\n",
    "    for batch_idx,data in enumerate(train_loader,0):\n",
    "        inputs,target = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs,target)\n",
    "        loss.backward()  #求梯度\n",
    "        optimizer.step() #更新权重\n",
    "        running_loss += loss.item()\n",
    "        if batch_idx%800==799:\n",
    "            print('[%d,%5d] loss:%.3f' % (epoch+1,batch_idx+1,running_loss/100))\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model,testloader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images,labels = data\n",
    "#             images,labels = images.to('cuda'),labels.to('cuda')\n",
    "            outputs = model(images)\n",
    "            _,predicted = torch.max(outputs.data,dim=1)\n",
    "            total += labels.size(0)\n",
    "            correct+=(predicted==labels).sum().item()\n",
    "        print(\"acc on train: %d %%\" % (100*correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  100] loss:3.580\n",
      "[1,  200] loss:3.573\n",
      "acc on train: 7 %\n",
      "[2,  100] loss:3.530\n",
      "[2,  200] loss:3.441\n",
      "acc on train: 12 %\n",
      "[3,  100] loss:2.902\n",
      "[3,  200] loss:2.064\n",
      "acc on train: 50 %\n",
      "[4,  100] loss:1.495\n",
      "[4,  200] loss:1.112\n",
      "acc on train: 73 %\n",
      "[5,  100] loss:0.722\n",
      "[5,  200] loss:0.612\n",
      "acc on train: 85 %\n",
      "[6,  100] loss:0.445\n",
      "[6,  200] loss:0.397\n",
      "acc on train: 86 %\n",
      "[7,  100] loss:0.303\n",
      "[7,  200] loss:0.293\n",
      "acc on train: 93 %\n",
      "[8,  100] loss:0.223\n",
      "[8,  200] loss:0.213\n",
      "acc on train: 96 %\n",
      "[9,  100] loss:0.190\n",
      "[9,  200] loss:0.157\n",
      "acc on train: 97 %\n",
      "[10,  100] loss:0.121\n",
      "[10,  200] loss:0.138\n",
      "acc on train: 98 %\n",
      "[11,  100] loss:0.083\n",
      "[11,  200] loss:0.144\n",
      "acc on train: 94 %\n",
      "[12,  100] loss:0.076\n",
      "[12,  200] loss:0.115\n",
      "acc on train: 98 %\n",
      "[13,  100] loss:0.057\n",
      "[13,  200] loss:0.055\n",
      "acc on train: 99 %\n",
      "[14,  100] loss:0.041\n",
      "[14,  200] loss:0.097\n",
      "acc on train: 99 %\n",
      "[15,  100] loss:0.030\n",
      "[15,  200] loss:0.057\n",
      "acc on train: 99 %\n",
      "[16,  100] loss:0.008\n",
      "[16,  200] loss:0.060\n",
      "acc on train: 99 %\n",
      "[17,  100] loss:0.012\n",
      "[17,  200] loss:0.064\n",
      "acc on train: 99 %\n",
      "[18,  100] loss:0.027\n",
      "[18,  200] loss:0.035\n",
      "acc on train: 99 %\n",
      "[19,  100] loss:0.011\n",
      "[19,  200] loss:0.029\n",
      "acc on train: 99 %\n",
      "[20,  100] loss:0.013\n",
      "[20,  200] loss:0.021\n",
      "acc on train: 98 %\n",
      "[21,  100] loss:0.016\n",
      "[21,  200] loss:0.090\n",
      "acc on train: 99 %\n",
      "[22,  100] loss:0.043\n",
      "[22,  200] loss:0.019\n",
      "acc on train: 99 %\n",
      "[23,  100] loss:0.014\n",
      "[23,  200] loss:0.044\n",
      "acc on train: 99 %\n",
      "[24,  100] loss:0.006\n",
      "[24,  200] loss:0.012\n",
      "acc on train: 99 %\n",
      "[25,  100] loss:0.003\n",
      "[25,  200] loss:0.074\n",
      "acc on train: 99 %\n",
      "[26,  100] loss:0.008\n",
      "[26,  200] loss:0.009\n",
      "acc on train: 99 %\n",
      "[27,  100] loss:0.009\n",
      "[27,  200] loss:0.005\n",
      "acc on train: 99 %\n",
      "[28,  100] loss:0.005\n",
      "[28,  200] loss:0.015\n",
      "acc on train: 100 %\n",
      "[29,  100] loss:0.002\n",
      "[29,  200] loss:0.001\n",
      "acc on train: 99 %\n",
      "[30,  100] loss:0.002\n",
      "[30,  200] loss:0.002\n",
      "acc on train: 99 %\n",
      "[31,  100] loss:0.003\n",
      "[31,  200] loss:0.002\n",
      "acc on train: 99 %\n",
      "[32,  100] loss:0.002\n",
      "[32,  200] loss:0.001\n",
      "acc on train: 100 %\n",
      "[33,  100] loss:0.006\n",
      "[33,  200] loss:0.002\n",
      "acc on train: 100 %\n",
      "[34,  100] loss:0.001\n",
      "[34,  200] loss:0.001\n",
      "acc on train: 99 %\n",
      "[35,  100] loss:0.001\n",
      "[35,  200] loss:0.001\n",
      "acc on train: 100 %\n",
      "[36,  100] loss:0.001\n",
      "[36,  200] loss:0.004\n",
      "acc on train: 100 %\n",
      "[37,  100] loss:0.001\n",
      "[37,  200] loss:0.002\n",
      "acc on train: 99 %\n",
      "[38,  100] loss:0.001\n",
      "[38,  200] loss:0.001\n",
      "acc on train: 100 %\n",
      "[39,  100] loss:0.001\n",
      "[39,  200] loss:0.001\n",
      "acc on train: 100 %\n",
      "[40,  100] loss:0.001\n",
      "[40,  200] loss:0.001\n",
      "acc on train: 100 %\n",
      "[41,  100] loss:0.000\n",
      "[41,  200] loss:0.001\n",
      "acc on train: 100 %\n",
      "[42,  100] loss:0.000\n",
      "[42,  200] loss:0.001\n",
      "acc on train: 100 %\n",
      "[43,  100] loss:0.001\n",
      "[43,  200] loss:0.000\n",
      "acc on train: 100 %\n",
      "[44,  100] loss:0.000\n",
      "[44,  200] loss:0.000\n",
      "acc on train: 100 %\n",
      "[45,  100] loss:0.000\n",
      "[45,  200] loss:0.000\n",
      "acc on train: 100 %\n",
      "[46,  100] loss:0.000\n",
      "[46,  200] loss:0.001\n",
      "acc on train: 99 %\n",
      "[47,  100] loss:0.000\n",
      "[47,  200] loss:0.001\n",
      "acc on train: 100 %\n",
      "[48,  100] loss:0.000\n",
      "[48,  200] loss:0.009\n",
      "acc on train: 99 %\n",
      "[49,  100] loss:0.162\n",
      "[49,  200] loss:0.038\n",
      "acc on train: 99 %\n",
      "[50,  100] loss:0.004\n",
      "[50,  200] loss:0.003\n",
      "acc on train: 94 %\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(50):\n",
    "    train(epoch,train_loader)\n",
    "#     test(model,validation_loader)\n",
    "    test(model,train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy is 0.1835\n"
     ]
    }
   ],
   "source": [
    "accuracy_test(model,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
